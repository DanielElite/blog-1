<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
	<head>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="author" content="lamour" />
		<title>Talking about Web Spider II</title>
		<link rel="shortcut icon" href="/favicon.ico" />
		<link href="/feed/" rel="alternate" title="lamour" type="application/atom+xml" />
		<link rel="stylesheet" href="/media/css/style.css" />
		<link rel="stylesheet" href="/media/css/highlight.css" />
		<script type="text/javascript" src="/media/js/jquery-1.7.1.min.js"></script>
	</head>
	<body>
		<div id="container">
			<div id="main" role="main">
				<header>
				<h1>Talking about Web Spider II</h1>
				</header>
				<nav>
				<span><a title="网站首页" class="" href="/">首页</a></span>
				<span><a title="文章分类" class="" href="/categories/">分类</a></span>
				<span><a title="标签索引" class="" href="/tags/">标签</a></span>
				<!--<span><a title="友情链接" class="" href="/links/">链接</a></span>-->
				<span><a title="留言交流" class="" href="/guestbook/">留言</a></span>
                                <!--<span><a title="订阅本站" class="" href="/feed.xml">订阅</a></span>-->
				<span><a title="关于站长" class="" href="/about/">关于</a></span>
				</nav>
				<article class="content">
				<section class="meta">
<span class="time">
  <time datetime="2016-02-03">2016-02-03</time>
</span>

 | 
<span class="categories">
  分类
  
  <a href="/categories/#HowTo" title="HowTo">HowTo</a>&nbsp;
  
</span>


 | 
<span class="tags">
  标签
  
  <a href="/tags/#知识回顾" title="知识回顾">知识回顾</a>&nbsp;
  
</span>

</section>
<section class="post">
<p><a href="http://iami.xyz/Python-Web-Spider-I">我的零开始</a></p>

<h2 id="section">一些库的简单使用</h2>
<ol>
  <li>urllib2(用来下载网页)
三种下载网页的方法
&gt; simply</li>
</ol>

<p>```python
         import urllib2</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    response = urllib2.urlopen('http://www.aol.com')         #直接请求
    
    print response.getcode()                              #看看状态码

    cont = response.read()                                #读取内容，可以在前面加个如果状态码有效 ``` &gt; Add Head, data
</code></pre>
</div>

<p>```python
        import urllib2</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    request = urllib2.Request(url)                  #创建request对象
    
    request.add_data('xxx','xxx')                   #增加数据
    
    request.add_header('User-Agent', 'Mozilla/5.0')     #伪装成浏览器
    
    response = urllibe2.urlopen(request)            #发送请求 ``` &gt; advance &gt;&gt; 其实就是Cookie,Proxy,Redirect相关的,分别是HTTPCookieProcessor , ProxyHandler , HTTPRedirectHandler 
</code></pre>
</div>

<p>```python
        import urllibe2, cookielib</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    cj = cookielib.CookieJar()
    
    opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
    
    urllib2.install_opener(opener)
    
    response = urllib2.urlopen("http://www.google.com/") ```
</code></pre>
</div>

<ol>
  <li>Beautifuk Soup (用来解析网页)
&gt;从一个Html网页创建一个Beautiful对象，然后可以搜索节点，find_all,find等可以访问节点的名称和属性。当然配合正则表达式更好</li>
</ol>

<blockquote>
  <blockquote>
    <p><code class="highlighter-rouge">&lt;a href='1111.html' class='article_link'&gt; python &lt;/a&gt;</code>像这一个节点名称为a，属性href为1111.html，属性class为article_link，而节点内容为python
&gt;创建beautifulSoup对象
        <code class="highlighter-rouge">from bs4 import BeautifulSoup</code>  <br />
        <code class="highlighter-rouge">soup = BeautifulSoup( html_doc,  'html.parser', from_encoding='utf-8' )</code>    <br />
&gt;搜索节点
»</p>
  </blockquote>
</blockquote>

<p><code class="highlighter-rouge">python
        find_all(nane, attrs, string)      
        node = soup.find_all('a')     
        soup.find_all('a', href='1111.html')
        soup.find_all('a', href= re.compile(r'/view/\d+\.htm'))     #正则匹配 
        soup.find_all ('div', class_= 'abc', string= 'Python')
</code></p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>访问节点信息
&gt;
        node.naem
        node[‘href’]
        node.get_text()</p>
    </blockquote>
  </blockquote>
</blockquote>

<ol>
  <li>连接数据库(前提是要安装好数据库)
&gt;PostgreSQL</li>
</ol>

<p>```python
        import psycopg2</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    conn = psycopg2.connect("dbname='dbname' user='username' host='localhost' password='password'")  

    cur = conn.cursor()  
    
    cur.execute("select * from dbtable")  
    
    for row in cur:  
    
         print row 
    
     conn.close()  ```
</code></pre>
</div>

<blockquote>
  <p>ms sql</p>
</blockquote>

<p>```python
        import psmssql</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    conn = psmssql.connect(host='yourhost', user='loginname', password='password', database='dbname', charset='utf8')  
    
    cur = conn.cursor()  
    
    cur.execute('select * from dbtable')  
    
    for row in cur:  

            print row 
    
    conn.close()  ```
</code></pre>
</div>

<blockquote>
  <p>mysql</p>
</blockquote>

<p>```python
        import MySQLdb</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    conn= MySQLdb.connect( host='localhost', port = 3306, user='username', passwd='password', db ='dbname',)
    
    cur = conn.cursor()
    
    cur.execute("delete from student where grade &gt; 30")
    
    cur.close()

    conn.commit()
    
    conn.close() ```
</code></pre>
</div>

<ul>
  <li>
    <p>资料补充</p>

    <p><a href="http://scrapy.org/">Scrapy</a></p>

    <p><a href="http://www.python-requests.org/">Requests</a></p>

    <p><a href="http://casperjs.org">CasperJS/PhantomJS</a></p>

    <p><a href="https://docs.python.org/3/library/html.parser.html">HtmlParser</a></p>

    <p><a href="http://www.zhihu.com/question/38192299">你见过那些瞠目结舌的爬虫技巧-知乎</a></p>

    <p>还可以使用一些web框架去写爬虫，例如flask，django（手撕包菜用的就是这个）,tornado</p>

    <p><a href="http://www.tornadoweb.org/en/stable/guide/queues.html">Tornado框架的爬虫示例</a>
  <a href="http://nutch.apache.org/">Nutch</a></p>

    <p>当然其他语言也可以写爬虫，java, ruby,php等，还有go啊，js啊</p>
  </li>
</ul>


</section>
<section align="right">
<br/>
<span>
	<a  href="/Jekyll-and-Markdown/" class="pageNav"  >上一篇</a>
	&nbsp;&nbsp;&nbsp;
	<a  href="/Python-Web-Spider-I/" class="pageNav"  >下一篇</a>
</span>
</section>

	
	<div class="ds-thread" />
		
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"lamour"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>


				</article>
			</div>

			<footer>
			<p><small>
				<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/cn/" target="_blank" title="许可协议">©</a> 2014 - 2016 <a href="/about/">lamour</a>
			</small></p>
			</footer>

		</div>
	</body>
</html>
